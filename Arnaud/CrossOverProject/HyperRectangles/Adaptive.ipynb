{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division\n",
    "from __future__ import print_function, unicode_literals\n",
    "import pints.toy as toy\n",
    "import pints\n",
    "import numpy as np\n",
    "import logging\n",
    "import math\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sys\n",
    "from numpy import inf\n",
    "import copy \n",
    "import pickle\n",
    "import time\n",
    "import CMA as CMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CMA_on_HyperRect_Homogeneous(opt, \n",
    "                 problem,\n",
    "                 sampler,\n",
    "                 sampler_x0, \n",
    "                 n_chains=1,\n",
    "                 chain_size=100,\n",
    "                 need_sensitivities=False, \n",
    "                eval_fun=['ESS']):\n",
    "    \n",
    "    optimizer_best_fxs = []\n",
    "    optimizer_best_xs = []\n",
    "    \n",
    "    optimizer_best_fx = np.inf\n",
    "    optimizer_best_x = 0\n",
    "    \n",
    "    for _ in range(50):\n",
    "        \n",
    "        # Getting the samples of hyper-parameters for the samplers\n",
    "        optimizer_xs = opt.ask()\n",
    "        \n",
    "        # Saving the score of each sample of hyper-parameters\n",
    "        optimizer_fxs = []\n",
    "        \n",
    "        # Evaluate performance for each hyper-parameter configuration\n",
    "        for x in optimizer_xs:\n",
    "            \n",
    "            our_x = x\n",
    "            \n",
    "            # Initialise function evaluations and matrix for chains\n",
    "            function_evaluations = 0 \n",
    "            chains = []\n",
    "            \n",
    "            # Return array of samples for each chain\n",
    "            for i in range(n_chains):\n",
    "\n",
    "                # Create sampler object and set hyperparameter\n",
    "                curr_x0 = sampler_x0[i]\n",
    "                mcmc = sampler(curr_x0)\n",
    "                mcmc.set_hyper_parameters([our_x, True])\n",
    "                i_chain = []\n",
    "                \n",
    "                # Update until we have ``chain_size`` samples\n",
    "                # Update function evaluations each time we use ask(),tell()\n",
    "                while len(i_chain) < chain_size:\n",
    "                    x = mcmc.ask()\n",
    "                    if need_sensitivities:\n",
    "                        fx, grad = problem.evaluateS1(x)\n",
    "                        sample = mcmc.tell((fx, grad))\n",
    "                    else:\n",
    "                        fx = problem.evaluateS1(x)\n",
    "                        sample = mcmc.tell(fx)\n",
    "                    function_evaluations += 1\n",
    "                    if sample is not None:\n",
    "                        i_chain.append(sample)\n",
    "                \n",
    "                # Append ith chain to list of chains       \n",
    "                chains.append(i_chain)\n",
    "                \n",
    "            chains = np.array(chains, copy=True)\n",
    "            optimizer_fx = 0\n",
    "            # Calculate the score of the sampler with the given hyper-parameters\n",
    "            # Get the KL if requested\n",
    "            if 'KL' in eval_fun:\n",
    "                kl = 0\n",
    "                for chain in chains:\n",
    "                    kl += problem.kl_divergence(chain)\n",
    "                optimizer_fx = kl/len(chains)                \n",
    "            \n",
    "            elif 'KL-ITER' in eval_fun:\n",
    "                kl = 0\n",
    "                for chain in chains:\n",
    "                    kl += problem.kl_divergence(chain)\n",
    "                avg_kl = kl/len(chains)\n",
    "                avg_iteration_count = function_evaluations / len(chains)\n",
    "                optimizer_fx = avg_kl * avg_iteration_count\n",
    "            \n",
    "            # Get the ESS if requested\n",
    "            elif 'ESS' in eval_fun:\n",
    "                ess = np.zeros(chains[0].shape[1])\n",
    "                for chain in chains:\n",
    "                    ess += np.array(pints._diagnostics.effective_sample_size(chain))\n",
    "                ess /= len(chains)\n",
    "                ess = np.min(ess)\n",
    "                avg_iteration_count = function_evaluations / len(chains)\n",
    "                optimizer_fx = math.sqrt(avg_iteration_count) / ess\n",
    "                \n",
    "            optimizer_fxs.append(optimizer_fx)\n",
    "        opt.tell(optimizer_fxs)\n",
    "        \n",
    "        optimizer_best_fxs.append(opt.fbest())\n",
    "        optimizer_best_xs.append(opt.xbest())\n",
    "        \n",
    "        if opt.fbest() < optimizer_best_fx:\n",
    "            optimizer_best_fx = opt.fbest()\n",
    "            optimizer_best_x = opt.xbest()\n",
    "    \n",
    "    print(optimizer_best_fx)\n",
    "    print(optimizer_best_x)\n",
    "    print()\n",
    "    \n",
    "    return optimizer_best_fxs, optimizer_best_xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score\n",
      "1.7127249311275041\n",
      "Best Hyper-Parameters\n",
      "[9.49495527 8.44916381]\n",
      "\n",
      "Best Score\n",
      "1.834308470251693\n",
      "Best Hyper-Parameters\n",
      "[0.26063598 0.05373724]\n",
      "\n",
      "Best Score\n",
      "1.9258250416771152\n",
      "Best Hyper-Parameters\n",
      "[0.10932187 0.48717175]\n",
      "\n",
      "Best Score\n",
      "1.7694521587367684\n",
      "Best Hyper-Parameters\n",
      "[8.71016373 8.24312221]\n",
      "\n",
      "Best Score\n",
      "1.8256559039416769\n",
      "Best Hyper-Parameters\n",
      "[7.90387507 9.64259045]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rosenbrock = pints.toy.RosenbrockLogPDF()\n",
    "eggshape = pints.toy.SimpleEggBoxLogPDF(2,4)\n",
    "Logistic = pints.toy.LogisticModel()\n",
    "\n",
    "problem = rosenbrock\n",
    "\n",
    "# Define the starting points of the samplers\n",
    "sampler_rosenbrock_x0 = xs = [\n",
    "    [0,0],\n",
    "    [3,8],\n",
    "    [2,4],\n",
    "]\n",
    "\n",
    "sampler_egg_x0 = xs = [\n",
    "    [-10,-10],\n",
    "    [0,0],\n",
    "    [10,10],\n",
    "]\n",
    "\n",
    "sampler_x0 = sampler_rosenbrock_x0\n",
    "\n",
    "# Define the starting point of the optimzer\n",
    "dummy = pints.SliceHyperrectanglesMCMC([2, 4])\n",
    "optimizer_x0 = [dummy.width()[0], dummy.width()[1]]\n",
    "\n",
    "boundary = pints.RectangularBoundaries([0,0],[20,20])\n",
    "\n",
    "sampler = pints.SliceHyperrectanglesMCMC\n",
    "\n",
    "for i in range(5):\n",
    "    cma = CMA.CMAES(optimizer_x0, boundaries=boundary)\n",
    "    fxs, xs =  CMA_on_HyperRect_Homogeneous(cma, problem, sampler, \n",
    "                        sampler_x0, n_chains=3, chain_size=100, eval_fun=['ESS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pints' has no attribute 'SliceHyperrectanglesMCMC'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-49143531b6a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define the starting point of the optimzer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdummy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSliceHyperrectanglesMCMC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0moptimizer_x0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdummy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_x0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pints' has no attribute 'SliceHyperrectanglesMCMC'"
     ]
    }
   ],
   "source": [
    "# Define the starting point of the optimzer\n",
    "dummy = pints.SliceHyperrectanglesMCMC([2, 4])\n",
    "optimizer_x0 = [dummy.width()[0], dummy.width()[1]]\n",
    "print(optimizer_x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for the EggShape problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.6633780365310231\n",
    "[8.53837666 9.14565402]\n",
    "\n",
    "0.671087654591173\n",
    "[10.17517565  9.21948061]\n",
    "\n",
    "0.6847802080854595\n",
    "[9.43201469 8.6194252 ]\n",
    "\n",
    "0.684552052087733\n",
    "[8.35683414 9.9708093 ]\n",
    "\n",
    "0.6862461492720475\n",
    "[10.09632839  8.42542171]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for the Rosenbrock Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-f244d5ce9110>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-f244d5ce9110>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Best Score\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "1.7127249311275041\n",
    "[9.49495527 8.44916381]\n",
    "\n",
    "1.834308470251693\n",
    "[0.26063598 0.05373724]\n",
    "\n",
    "1.9258250416771152\n",
    "[0.10932187 0.48717175]\n",
    "\n",
    "1.7694521587367684\n",
    "[8.71016373 8.24312221]\n",
    "\n",
    "1.8256559039416769\n",
    "[7.90387507 9.64259045]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Model and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pints\n",
    "import pints.toy as toy\n",
    "import pints.plot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ExampleModel(pints.ForwardModel):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = toy.LogisticModel()\n",
    "    def simulate(self, x, times):\n",
    "        return self.model.simulate([x[0]/1000, x[1]], times)\n",
    "    def simulateS1(self, x, times):\n",
    "        values, gradient = self.model.simulateS1([x[0]/1000, x[1]], times)\n",
    "        return values, gradient\n",
    "    def n_parameters(self):\n",
    "        return 2\n",
    "\n",
    "# Then create an instance of our new model class\n",
    "model = ExampleModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some toy data\n",
    "real_parameters = [0.015*10000, 500]\n",
    "times = np.linspace(0, 1000, 1000)\n",
    "org_values = model.simulate(real_parameters, times)\n",
    "\n",
    "# Add noise\n",
    "noise = 10\n",
    "values = org_values + np.random.normal(0, noise, org_values.shape)\n",
    "real_parameters = np.array(real_parameters + [noise])\n",
    "\n",
    "# Get properties of the noise sample\n",
    "noise_sample_mean = np.mean(values - org_values)\n",
    "noise_sample_std = np.std(values - org_values)\n",
    "\n",
    "# Create an object with links to the model and time series\n",
    "problem = pints.SingleOutputProblem(model, times, values)\n",
    "\n",
    "# Create a log-likelihood function (adds an extra parameter!)\n",
    "log_likelihood = pints.GaussianLogLikelihood(problem)\n",
    "\n",
    "# Create a uniform prior over both the parameters and the new noise variable\n",
    "log_prior = pints.UniformLogPrior(\n",
    "    [0.01*10000, 400, noise * 0.1],\n",
    "    [0.02*10000, 600, noise * 100],\n",
    ")\n",
    "\n",
    "# Create a posterior log-likelihood (log(likelihood * prior))\n",
    "log_posterior = pints.LogPosterior(log_likelihood, log_prior)\n",
    "\n",
    "# Choose starting points for 3 mcmc chains\n",
    "num_chains = 3\n",
    "sampler_logistic_x0 = [\n",
    "    real_parameters * 1.01,\n",
    "    real_parameters * 0.99,\n",
    "    real_parameters * 1.01\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naunauyoh/anaconda3/lib/python3.7/site-packages/pints/_log_likelihoods.py:476: RuntimeWarning: invalid value encountered in log\n",
      "  - np.sum(error**2, axis=0) / (2 * sigma**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5602994194803705\n",
      "[5.61401202 4.22481883 0.75674336]\n",
      "\n",
      "1.685472660356954\n",
      "[7.34162696 4.48995497 0.74637457]\n",
      "\n",
      "1.654779618231904\n",
      "[8.6941372  3.66687751 1.00450451]\n",
      "\n",
      "1.4898493920617981\n",
      "[13.46896167  4.57889999  1.00920944]\n",
      "\n",
      "1.7148956776000917\n",
      "[11.92137682  7.60302896  0.91595197]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "problem = log_posterior\n",
    "\n",
    "sampler_x0 = sampler_logistic_x0\n",
    "\n",
    "# Define the starting point of the optimzer\n",
    "dummy = pints.SliceHyperrectanglesMCMC([2, 4, 10])\n",
    "optimizer_x0 = [dummy.width()[0], dummy.width()[1], dummy.width()[2]]\n",
    "\n",
    "boundary = pints.RectangularBoundaries([0,0,0],[20,20,20])\n",
    "\n",
    "sampler = pints.SliceHyperrectanglesMCMC\n",
    "\n",
    "for i in range(5):\n",
    "    cma = CMA.CMAES(optimizer_x0, boundaries=boundary)\n",
    "    fxs, xs =  CMA_on_HyperRect_Homogeneous(cma, problem, sampler, \n",
    "                        sampler_x0, n_chains=3, chain_size=100, eval_fun=['ESS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.5602994194803705\n",
    "[5.61401202 4.22481883 0.75674336]\n",
    "\n",
    "1.685472660356954\n",
    "[7.34162696 4.48995497 0.74637457]\n",
    "\n",
    "1.654779618231904\n",
    "[8.6941372  3.66687751 1.00450451]\n",
    "\n",
    "1.4898493920617981\n",
    "[13.46896167  4.57889999  1.00920944]\n",
    "\n",
    "1.7148956776000917\n",
    "[11.92137682  7.60302896  0.91595197]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
