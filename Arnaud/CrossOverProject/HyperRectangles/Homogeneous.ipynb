{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division\n",
    "from __future__ import print_function, unicode_literals\n",
    "import pints.toy as toy\n",
    "import pints\n",
    "import numpy as np\n",
    "import logging\n",
    "import math\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sys\n",
    "from numpy import inf\n",
    "import copy \n",
    "import pickle\n",
    "import time\n",
    "import CMA as CMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CMA_on_HyperRect_Homogeneous(opt, \n",
    "                 problem,\n",
    "                 sampler,\n",
    "                 sampler_x0, \n",
    "                 n_chains=1,\n",
    "                 chain_size=100,\n",
    "                 need_sensitivities=False, \n",
    "                eval_fun=['ESS']):\n",
    "    \n",
    "    optimizer_best_fxs = []\n",
    "    optimizer_best_xs = []\n",
    "    \n",
    "    optimizer_best_fx = np.inf\n",
    "    optimizer_best_x = 0\n",
    "    \n",
    "    for _ in range(50):\n",
    "        \n",
    "        # Getting the samples of hyper-parameters for the samplers\n",
    "        optimizer_xs = opt.ask()\n",
    "        \n",
    "        # Saving the score of each sample of hyper-parameters\n",
    "        optimizer_fxs = []\n",
    "        \n",
    "        # Evaluate performance for each hyper-parameter configuration\n",
    "        for x in optimizer_xs:\n",
    "            \n",
    "            our_x = [[x[0], x[1]], False]\n",
    "            \n",
    "            # Initialise function evaluations and matrix for chains\n",
    "            function_evaluations = 0 \n",
    "            chains = []\n",
    "            \n",
    "            # Return array of samples for each chain\n",
    "            for i in range(n_chains):\n",
    "\n",
    "                # Create sampler object and set hyperparameter\n",
    "                curr_x0 = sampler_x0[i]\n",
    "                mcmc = sampler(curr_x0)\n",
    "                mcmc.set_hyper_parameters(our_x)\n",
    "                i_chain = []\n",
    "                \n",
    "                # Update until we have ``chain_size`` samples\n",
    "                # Update function evaluations each time we use ask(),tell()\n",
    "                while len(i_chain) < chain_size:\n",
    "                    x = mcmc.ask()\n",
    "                    if need_sensitivities:\n",
    "                        fx, grad = problem.evaluateS1(x)\n",
    "                        sample = mcmc.tell((fx, grad))\n",
    "                    else:\n",
    "                        fx = problem.evaluateS1(x)\n",
    "                        sample = mcmc.tell(fx)\n",
    "                    function_evaluations += 1\n",
    "                    if sample is not None:\n",
    "                        i_chain.append(sample)\n",
    "                \n",
    "                # Append ith chain to list of chains       \n",
    "                chains.append(i_chain)\n",
    "                \n",
    "            chains = np.array(chains, copy=True)\n",
    "            optimizer_fx = 0\n",
    "            # Calculate the score of the sampler with the given hyper-parameters\n",
    "            # Get the KL if requested\n",
    "            if 'KL' in eval_fun:\n",
    "                kl = 0\n",
    "                for chain in chains:\n",
    "                    kl += problem.kl_divergence(chain)\n",
    "                optimizer_fx = kl/len(chains)                \n",
    "            \n",
    "            elif 'KL-ITER' in eval_fun:\n",
    "                kl = 0\n",
    "                for chain in chains:\n",
    "                    kl += problem.kl_divergence(chain)\n",
    "                avg_kl = kl/len(chains)\n",
    "                avg_iteration_count = function_evaluations / len(chains)\n",
    "                optimizer_fx = avg_kl * avg_iteration_count\n",
    "            \n",
    "            # Get the ESS if requested\n",
    "            elif 'ESS' in eval_fun:\n",
    "                ess = np.zeros(chains[0].shape[1])\n",
    "                for chain in chains:\n",
    "                    ess += np.array(pints._diagnostics.effective_sample_size(chain))\n",
    "                ess /= len(chains)\n",
    "                ess = np.min(ess)\n",
    "                avg_iteration_count = function_evaluations / len(chains)\n",
    "                optimizer_fx = math.sqrt(avg_iteration_count) / ess\n",
    "                \n",
    "            optimizer_fxs.append(optimizer_fx)\n",
    "        opt.tell(optimizer_fxs)\n",
    "        \n",
    "        optimizer_best_fxs.append(opt.fbest())\n",
    "        optimizer_best_xs.append(opt.xbest())\n",
    "        \n",
    "        if opt.fbest() < optimizer_best_fx:\n",
    "            optimizer_best_fx = opt.fbest()\n",
    "            optimizer_best_x = opt.xbest()\n",
    "    \n",
    "    print(optimizer_best_fx)\n",
    "    print(optimizer_best_x)\n",
    "    print()\n",
    "    \n",
    "    return optimizer_best_fxs, optimizer_best_xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6954018606609961\n",
      "[9.21391654 9.02364727]\n",
      "\n",
      "0.6797860425897491\n",
      "[11.36316537  9.10693217]\n",
      "\n",
      "0.6864313595714472\n",
      "[9.56691377 9.44077568]\n",
      "\n",
      "0.696544483132432\n",
      "[12.29495318 11.64797848]\n",
      "\n",
      "0.658750850245878\n",
      "[9.16495498 9.71272276]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rosenbrock = pints.toy.RosenbrockLogPDF()\n",
    "eggshape = pints.toy.SimpleEggBoxLogPDF(2,4)\n",
    "Logistic = pints.toy.LogisticModel()\n",
    "\n",
    "problem = eggshape\n",
    "\n",
    "# Define the starting points of the samplers\n",
    "sampler_rosenbrock_x0 = xs = [\n",
    "    [0,0],\n",
    "    [3,8],\n",
    "    [2,4],\n",
    "]\n",
    "\n",
    "sampler_egg_x0 = xs = [\n",
    "    [-10,-10],\n",
    "    [0,0],\n",
    "    [10,10],\n",
    "]\n",
    "\n",
    "sampler_x0 = sampler_egg_x0\n",
    "\n",
    "# Define the starting point of the optimzer\n",
    "dummy = pints.SliceHyperrectanglesMCMC([2, 4])\n",
    "optimizer_x0 = [dummy.width()[0], dummy.width()[1]]\n",
    "\n",
    "boundary = pints.RectangularBoundaries([0,0],[20,20])\n",
    "\n",
    "sampler = pints.SliceHyperrectanglesMCMC\n",
    "\n",
    "for i in range(5):\n",
    "    cma = CMA.CMAES(optimizer_x0, boundaries=boundary)\n",
    "    fxs, xs =  CMA_on_HyperRect_Homogeneous(cma, problem, sampler, \n",
    "                        sampler_x0, n_chains=3, chain_size=100, eval_fun=['ESS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for the Rosenbrock Problem using different Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg_iteration count over ESS\n",
    "39.22133186462336\n",
    "[0.54406868 0.87978578]\n",
    "35.19997635159976\n",
    "[0.65310227 0.96749411]\n",
    "19.32533975593854\n",
    "[0.02304884 0.09199689]\n",
    "25.59287940905728\n",
    "[0.00087682 0.18857804]\n",
    "40.2368614691648\n",
    "[0.99958012 0.58758153]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 over ESS\n",
    "0.060240947544655324\n",
    "[6.88960141 7.87139767]\n",
    "\n",
    "0.05855631030168425\n",
    "[11.34852473 19.34966525]\n",
    "\n",
    "0.05478297275859089\n",
    "[14.40292733 12.15825586]\n",
    "\n",
    "0.05240072296170241\n",
    "[14.78413561 16.09348001]\n",
    "\n",
    "0.060761246693836375\n",
    "[14.07404409  9.92222866]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqrt(avg_ieration) over ESS\n",
    "0.6579954014060239\n",
    "[9.44235379 8.82797313]\n",
    "\n",
    "0.6747332577632024\n",
    "[10.04051936  9.21943616]\n",
    "\n",
    "0.6754667829729044\n",
    "[8.29234221 8.26721892]\n",
    "\n",
    "0.693838312255056\n",
    "[8.15209441 7.4049454 ]\n",
    "\n",
    "0.6733647984144733\n",
    "[8.86375154 9.24731263]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for the egg Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.6954018606609961\n",
    "[9.21391654 9.02364727]\n",
    "\n",
    "0.6797860425897491\n",
    "[11.36316537  9.10693217]\n",
    "\n",
    "0.6864313595714472\n",
    "[9.56691377 9.44077568]\n",
    "\n",
    "0.696544483132432\n",
    "[12.29495318 11.64797848]\n",
    "\n",
    "0.658750850245878\n",
    "[9.16495498 9.71272276]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Model Problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pints\n",
    "import pints.toy as toy\n",
    "import pints.plot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ExampleModel(pints.ForwardModel):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = toy.LogisticModel()\n",
    "    def simulate(self, x, times):\n",
    "        return self.model.simulate([x[0]/1000, x[1]], times)\n",
    "    def simulateS1(self, x, times):\n",
    "        values, gradient = self.model.simulateS1([x[0]/1000, x[1]], times)\n",
    "        return values, gradient\n",
    "    def n_parameters(self):\n",
    "        return 2\n",
    "\n",
    "# Then create an instance of our new model class\n",
    "model = ExampleModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some toy data\n",
    "real_parameters = [0.015*10000, 500]\n",
    "times = np.linspace(0, 1000, 1000)\n",
    "org_values = model.simulate(real_parameters, times)\n",
    "\n",
    "# Add noise\n",
    "noise = 10\n",
    "values = org_values + np.random.normal(0, noise, org_values.shape)\n",
    "real_parameters = np.array(real_parameters + [noise])\n",
    "\n",
    "# Get properties of the noise sample\n",
    "noise_sample_mean = np.mean(values - org_values)\n",
    "noise_sample_std = np.std(values - org_values)\n",
    "\n",
    "# Create an object with links to the model and time series\n",
    "problem = pints.SingleOutputProblem(model, times, values)\n",
    "\n",
    "# Create a log-likelihood function (adds an extra parameter!)\n",
    "log_likelihood = pints.GaussianLogLikelihood(problem)\n",
    "\n",
    "# Create a uniform prior over both the parameters and the new noise variable\n",
    "log_prior = pints.UniformLogPrior(\n",
    "    [0.01*10000, 400, noise * 0.1],\n",
    "    [0.02*10000, 600, noise * 100],\n",
    ")\n",
    "\n",
    "# Create a posterior log-likelihood (log(likelihood * prior))\n",
    "log_posterior = pints.LogPosterior(log_likelihood, log_prior)\n",
    "\n",
    "# Choose starting points for 3 mcmc chains\n",
    "num_chains = 3\n",
    "sampler_logistic_x0 = [\n",
    "    real_parameters * 1.01,\n",
    "    real_parameters * 0.99,\n",
    "    real_parameters * 1.01\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.171352545031565\n",
      "[16.80640373 15.0343616   7.34175251]\n",
      "\n",
      "1.1215557984532354\n",
      "[4.92052093 6.28257363 2.88642057]\n",
      "\n",
      "1.1720671160551777\n",
      "[12.00490911 10.0007691   6.4452416 ]\n",
      "\n",
      "1.0858744291049671\n",
      "[6.39426966 6.9034228  2.79639242]\n",
      "\n",
      "1.0997394181683062\n",
      "[6.64677631 5.13585011 4.18637856]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "problem = log_posterior\n",
    "\n",
    "sampler_x0 = sampler_logistic_x0\n",
    "\n",
    "# Define the starting point of the optimzer\n",
    "dummy = pints.SliceHyperrectanglesMCMC([2, 4, 10])\n",
    "optimizer_x0 = [dummy.width()[0], dummy.width()[1], dummy.width()[2]]\n",
    "\n",
    "boundary = pints.RectangularBoundaries([0,0,0],[20,20,20])\n",
    "\n",
    "sampler = pints.SliceHyperrectanglesMCMC\n",
    "\n",
    "for i in range(5):\n",
    "    cma = CMA.CMAES(optimizer_x0, boundaries=boundary)\n",
    "    fxs, xs =  CMA_on_HyperRect_Homogeneous(cma, problem, sampler, \n",
    "                        sampler_x0, n_chains=3, chain_size=100, eval_fun=['ESS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.171352545031565\n",
    "[16.80640373 15.0343616   7.34175251]\n",
    "\n",
    "1.1215557984532354\n",
    "[4.92052093 6.28257363 2.88642057]\n",
    "\n",
    "1.1720671160551777\n",
    "[12.00490911 10.0007691   6.4452416 ]\n",
    "\n",
    "1.0858744291049671\n",
    "[6.39426966 6.9034228  2.79639242]\n",
    "\n",
    "1.0997394181683062\n",
    "[6.64677631 5.13585011 4.18637856]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
