{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division\n",
    "from __future__ import print_function, unicode_literals\n",
    "import pints.toy as toy\n",
    "import pints\n",
    "import numpy as np\n",
    "import logging\n",
    "import math\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sys\n",
    "from numpy import inf\n",
    "import copy \n",
    "import pickle\n",
    "import time\n",
    "import CMA as CMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CMA_on_single_var(opt, \n",
    "                 problem,\n",
    "                 sampler,\n",
    "                 sampler_x0, \n",
    "                 n_chains=1,\n",
    "                 chain_size=100,\n",
    "                 need_sensitivities=False, \n",
    "                eval_fun=['ESS']):\n",
    "    \n",
    "    optimizer_best_fxs = []\n",
    "    optimizer_best_xs = []\n",
    "    \n",
    "    optimizer_best_fx = np.inf\n",
    "    optimizer_best_x = 0\n",
    "    \n",
    "    for _ in range(100):\n",
    "        \n",
    "        # Getting the samples of hyper-parameters for the samplers\n",
    "        optimizer_xs = opt.ask()\n",
    "        \n",
    "        # Saving the score of each sample of hyper-parameters\n",
    "        optimizer_fxs = []\n",
    "        \n",
    "        # Evaluate performance for each hyper-parameter configuration\n",
    "        for x in optimizer_xs:\n",
    "            \n",
    "            #our_x = [[x[0], x[1], x[2]], x[3]]\n",
    "            our_x = [[x[0], x[1]], x[2]]\n",
    "            \n",
    "            # Initialise function evaluations and matrix for chains\n",
    "            function_evaluations = 0 \n",
    "            chains = []\n",
    "            \n",
    "            # Return array of samples for each chain\n",
    "            for i in range(n_chains):\n",
    "\n",
    "                # Create sampler object and set hyperparameter\n",
    "                curr_x0 = sampler_x0[i]\n",
    "                mcmc = sampler(curr_x0)\n",
    "                mcmc.set_hyper_parameters(our_x)\n",
    "                i_chain = []\n",
    "                \n",
    "                # Update until we have ``chain_size`` samples\n",
    "                # Update function evaluations each time we use ask(),tell()\n",
    "                while len(i_chain) < chain_size:\n",
    "                    x = mcmc.ask()\n",
    "                    if need_sensitivities:\n",
    "                        fx, grad = problem.evaluateS1(x)\n",
    "                        sample = mcmc.tell((fx, grad))\n",
    "                    else:\n",
    "                        fx, _ = problem.evaluateS1(x)\n",
    "                        sample = mcmc.tell(fx)\n",
    "                    function_evaluations += 1\n",
    "                    if sample is not None:\n",
    "                        i_chain.append(sample)\n",
    "                \n",
    "                # Append ith chain to list of chains       \n",
    "                chains.append(i_chain)\n",
    "                \n",
    "            chains = np.array(chains, copy=True)\n",
    "            optimizer_fx = 0\n",
    "            # Calculate the score of the sampler with the given hyper-parameters\n",
    "            # Get the KL if requested\n",
    "            if 'KL' in eval_fun:\n",
    "                kl = 0\n",
    "                for chain in chains:\n",
    "                    kl += problem.kl_divergence(chain)\n",
    "                optimizer_fx = kl/len(chains)                \n",
    "            \n",
    "            elif 'KL-ITER' in eval_fun:\n",
    "                kl = 0\n",
    "                for chain in chains:\n",
    "                    kl += problem.kl_divergence(chain)\n",
    "                avg_kl = kl/len(chains)\n",
    "                avg_iteration_count = function_evaluations / len(chains)\n",
    "                optimizer_fx = avg_kl * avg_iteration_count\n",
    "            \n",
    "            # Get the ESS with Iteration if requested\n",
    "            elif 'ESS-ITER' in eval_fun:\n",
    "                ess = np.zeros(chains[0].shape[1])\n",
    "                for chain in chains:\n",
    "                    ess += np.array(pints._diagnostics.effective_sample_size(chain))\n",
    "                ess /= len(chains)\n",
    "                ess = np.min(ess)\n",
    "                avg_iteration_count = function_evaluations / len(chains)\n",
    "                optimizer_fx = math.sqrt(avg_iteration_count) / ess\n",
    "            \n",
    "            # Get the ESS if requested\n",
    "            elif 'ESS' in eval_fun:\n",
    "                ess = np.zeros(chains[0].shape[1])\n",
    "                for chain in chains:\n",
    "                    ess += np.array(pints._diagnostics.effective_sample_size(chain))\n",
    "                ess /= len(chains)\n",
    "                ess = np.min(ess)\n",
    "                optimizer_fx = 1 / ess\n",
    "            \n",
    "            optimizer_fxs.append(optimizer_fx)\n",
    "        opt.tell(optimizer_fxs)\n",
    "        \n",
    "        optimizer_best_fxs.append(opt.fbest())\n",
    "        optimizer_best_xs.append(opt.xbest())\n",
    "        \n",
    "        if opt.fbest() < optimizer_best_fx:\n",
    "            optimizer_best_fx = opt.fbest()\n",
    "            optimizer_best_x = opt.xbest()\n",
    "    \n",
    "    print(optimizer_best_fx)\n",
    "    print(optimizer_best_x)\n",
    "    print()\n",
    "    \n",
    "    return optimizer_best_fxs, optimizer_best_xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4185921572602609\n",
      "[3.55781155 4.59970624 1.87134159]\n",
      "\n",
      "SCORES [3.4209690809498245, 3.4209690809498245, 3.4209690809498245, 3.4209690809498245, 3.037768384656112, 3.037768384656112, 3.037768384656112, 3.037768384656112, 3.037768384656112, 3.037768384656112, 3.037768384656112, 3.037768384656112, 3.037768384656112, 3.037768384656112, 3.037768384656112, 3.037768384656112, 3.037768384656112, 3.037768384656112, 3.037768384656112, 3.037768384656112, 3.037768384656112, 3.037768384656112, 3.037768384656112, 1.6366424919586287, 1.6366424919586287, 1.6366424919586287, 1.6366424919586287, 1.6366424919586287, 1.6366424919586287, 1.6366424919586287, 1.6366424919586287, 1.6366424919586287, 1.6366424919586287, 1.6366424919586287, 1.6366424919586287, 1.6366424919586287, 1.6366424919586287, 1.6366424919586287, 1.6366424919586287, 1.6366424919586287, 1.6366424919586287, 1.6366424919586287, 1.6366424919586287, 1.6366424919586287, 1.4185921572602609, 1.4185921572602609, 1.4185921572602609, 1.4185921572602609, 1.4185921572602609, 1.4185921572602609]\n",
      "PARAMS [array([19.73538714, 19.82101311, 10.06682956]), array([19.73538714, 19.82101311, 10.06682956]), array([19.73538714, 19.82101311, 10.06682956]), array([19.73538714, 19.82101311, 10.06682956]), array([ 9.79104614, 18.06754303,  9.63054627]), array([ 9.79104614, 18.06754303,  9.63054627]), array([ 9.79104614, 18.06754303,  9.63054627]), array([ 9.79104614, 18.06754303,  9.63054627]), array([ 9.79104614, 18.06754303,  9.63054627]), array([ 9.79104614, 18.06754303,  9.63054627]), array([ 9.79104614, 18.06754303,  9.63054627]), array([ 9.79104614, 18.06754303,  9.63054627]), array([ 9.79104614, 18.06754303,  9.63054627]), array([ 9.79104614, 18.06754303,  9.63054627]), array([ 9.79104614, 18.06754303,  9.63054627]), array([ 9.79104614, 18.06754303,  9.63054627]), array([ 9.79104614, 18.06754303,  9.63054627]), array([ 9.79104614, 18.06754303,  9.63054627]), array([ 9.79104614, 18.06754303,  9.63054627]), array([ 9.79104614, 18.06754303,  9.63054627]), array([ 9.79104614, 18.06754303,  9.63054627]), array([ 9.79104614, 18.06754303,  9.63054627]), array([ 9.79104614, 18.06754303,  9.63054627]), array([3.54273987, 6.24695762, 1.54398404]), array([3.54273987, 6.24695762, 1.54398404]), array([3.54273987, 6.24695762, 1.54398404]), array([3.54273987, 6.24695762, 1.54398404]), array([3.54273987, 6.24695762, 1.54398404]), array([3.54273987, 6.24695762, 1.54398404]), array([3.54273987, 6.24695762, 1.54398404]), array([3.54273987, 6.24695762, 1.54398404]), array([3.54273987, 6.24695762, 1.54398404]), array([3.54273987, 6.24695762, 1.54398404]), array([3.54273987, 6.24695762, 1.54398404]), array([3.54273987, 6.24695762, 1.54398404]), array([3.54273987, 6.24695762, 1.54398404]), array([3.54273987, 6.24695762, 1.54398404]), array([3.54273987, 6.24695762, 1.54398404]), array([3.54273987, 6.24695762, 1.54398404]), array([3.54273987, 6.24695762, 1.54398404]), array([3.54273987, 6.24695762, 1.54398404]), array([3.54273987, 6.24695762, 1.54398404]), array([3.54273987, 6.24695762, 1.54398404]), array([3.54273987, 6.24695762, 1.54398404]), array([3.55781155, 4.59970624, 1.87134159]), array([3.55781155, 4.59970624, 1.87134159]), array([3.55781155, 4.59970624, 1.87134159]), array([3.55781155, 4.59970624, 1.87134159]), array([3.55781155, 4.59970624, 1.87134159]), array([3.55781155, 4.59970624, 1.87134159])]\n"
     ]
    }
   ],
   "source": [
    "rosenbrock = pints.toy.RosenbrockLogPDF()\n",
    "eggshape = pints.toy.SimpleEggBoxLogPDF(2,4)\n",
    "Logistic = pints.toy.LogisticModel()\n",
    "\n",
    "problem = eggshape\n",
    "\n",
    "# Define the starting points of the samplers\n",
    "sampler_rosenbrock_x0 = [\n",
    "    [0,0],\n",
    "    [3,8],\n",
    "    [2,4],\n",
    "]\n",
    "\n",
    "sampler_egg_x0 = [\n",
    "    [-10,-10],\n",
    "    [0,0],\n",
    "    [10,10],\n",
    "]\n",
    "\n",
    "sampler_x0 = sampler_egg_x0\n",
    "\n",
    "# Define the starting point of the optimzer\n",
    "dummy = pints.SliceDoublingMCMC([2, 4])\n",
    "optimizer_x0 = [dummy.width()[0], dummy.width()[1], dummy.expansion_steps()]\n",
    "boundary = pints.RectangularBoundaries([0,0,1],[20,20,50])\n",
    "\n",
    "sampler = pints.SliceDoublingMCMC\n",
    "\n",
    "for i in range(1):\n",
    "    cma = CMA.CMAES(optimizer_x0, boundaries=boundary)\n",
    "    fxs, xs =  CMA_on_single_var(cma, problem, sampler, \n",
    "                        sampler_x0, n_chains=3, chain_size=500, eval_fun=['ESS-ITER'])\n",
    "    print(\"SCORES\", fxs)\n",
    "    print(\"PARAMS\", xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2, 0.4, 10]\n"
     ]
    }
   ],
   "source": [
    "dummy = pints.SliceDoublingMCMC([2, 4])\n",
    "optimizer_x0 = [dummy.width()[0], dummy.width()[1], dummy.expansion_steps()]\n",
    "print(optimizer_x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for the Rosenbrock Problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.65165856770783\n",
    "[7.66063406 7.94001634 6.32656355]\n",
    "\n",
    "2.547566318306533\n",
    "[ 4.16839149  5.68204453 10.61587009]\n",
    "\n",
    "2.610463537959919\n",
    "[ 3.05592567  4.41440798 12.79150919]\n",
    "\n",
    "2.6958410930908703\n",
    "[ 8.473456    3.58357067 11.72819232]\n",
    "\n",
    "2.81859260274518\n",
    "[ 1.53479358  1.62903019 15.31999008]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for the Egg Shape Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.4096887136687746\n",
    "[5.26178205 5.45247427 1.92230768]\n",
    "\n",
    "1.3147810455223032\n",
    "[5.94037614 7.62648458 1.75172792]\n",
    "\n",
    "1.3489126362505708\n",
    "[6.14576926 5.59790442 1.57472481]\n",
    "\n",
    "1.4114654502722221\n",
    "[5.1707506  5.01498032 1.86376232]\n",
    "\n",
    "1.4028370578703422\n",
    "[4.87842409 6.21041138 1.11259927]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pints\n",
    "import pints.toy as toy\n",
    "import pints.plot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ExampleModel(pints.ForwardModel):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = toy.LogisticModel()\n",
    "    def simulate(self, x, times):\n",
    "        return self.model.simulate([x[0]/1000, x[1]], times)\n",
    "    def simulateS1(self, x, times):\n",
    "        values, gradient = self.model.simulateS1([x[0]/1000, x[1]], times)\n",
    "        return values, gradient\n",
    "    def n_parameters(self):\n",
    "        return 2\n",
    "\n",
    "# Then create an instance of our new model class\n",
    "model = ExampleModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some toy data\n",
    "real_parameters = [0.015*10000, 500]\n",
    "times = np.linspace(0, 1000, 1000)\n",
    "org_values = model.simulate(real_parameters, times)\n",
    "\n",
    "# Add noise\n",
    "noise = 10\n",
    "values = org_values + np.random.normal(0, noise, org_values.shape)\n",
    "real_parameters = np.array(real_parameters + [noise])\n",
    "\n",
    "# Get properties of the noise sample\n",
    "noise_sample_mean = np.mean(values - org_values)\n",
    "noise_sample_std = np.std(values - org_values)\n",
    "\n",
    "# Create an object with links to the model and time series\n",
    "problem = pints.SingleOutputProblem(model, times, values)\n",
    "\n",
    "# Create a log-likelihood function (adds an extra parameter!)\n",
    "log_likelihood = pints.GaussianLogLikelihood(problem)\n",
    "\n",
    "# Create a uniform prior over both the parameters and the new noise variable\n",
    "log_prior = pints.UniformLogPrior(\n",
    "    [0.01*10000, 400, noise * 0.1],\n",
    "    [0.02*10000, 600, noise * 100],\n",
    ")\n",
    "\n",
    "# Create a posterior log-likelihood (log(likelihood * prior))\n",
    "log_posterior = pints.LogPosterior(log_likelihood, log_prior)\n",
    "\n",
    "# Choose starting points for 3 mcmc chains\n",
    "num_chains = 3\n",
    "sampler_logistic_x0 = [\n",
    "    real_parameters * 1.01,\n",
    "    real_parameters * 0.99,\n",
    "    real_parameters * 1.01\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = log_posterior\n",
    "\n",
    "sampler_x0 = sampler_logistic_x0\n",
    "\n",
    "# Define the starting point of the optimzer\n",
    "dummy = pints.SliceDoublingMCMC([2, 4, 10])\n",
    "optimizer_x0 = [dummy.width()[0], dummy.width()[1], dummy.width()[2], dummy.expansion_steps()]\n",
    "\n",
    "\n",
    "boundary = pints.RectangularBoundaries([0,0,0,1],[20,20,20,15])\n",
    "\n",
    "sampler = pints.SliceDoublingMCMC\n",
    "\n",
    "for i in range(5):\n",
    "    cma = CMA.CMAES(optimizer_x0, boundaries=boundary)\n",
    "    fxs, xs =  CMA_on_single_var(cma, problem, sampler, \n",
    "                        sampler_x0, n_chains=3, chain_size=100, eval_fun=['ESS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2, 0.4, 1.0, 10]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dummy = pints.SliceDoublingMCMC([2, 4, 10])\n",
    "optimizer_x0 = [dummy.width()[0], dummy.width()[1], dummy.width()[2], dummy.expansion_steps()]\n",
    "print(optimizer_x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.6217118439833906\n",
    "[3.17171131 6.3090571  4.28788366 4.73189072]\n",
    "\n",
    "1.6093355480002016\n",
    "[18.84696198  5.68989611  5.32926045 10.56924945]\n",
    "\n",
    "1.6182910721347594\n",
    "[6.86305237 7.03818512 1.36405241 8.93229663]\n",
    "\n",
    "1.6131251090905396\n",
    "[10.83416564  3.64714311  4.65312227  6.31316515]\n",
    "\n",
    "1.618273135380834\n",
    "[10.70865917 15.1015873   2.57134735 14.77128816]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
