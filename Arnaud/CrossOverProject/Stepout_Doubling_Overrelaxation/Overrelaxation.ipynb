{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division\n",
    "from __future__ import print_function, unicode_literals\n",
    "import pints.toy as toy\n",
    "import pints\n",
    "import numpy as np\n",
    "import logging\n",
    "import math\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sys\n",
    "from numpy import inf\n",
    "import copy \n",
    "import pickle\n",
    "import time\n",
    "import CMA as CMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CMA_on_single_var(opt, \n",
    "                 problem,\n",
    "                 sampler,\n",
    "                 sampler_x0, \n",
    "                 n_chains=1,\n",
    "                 chain_size=100,\n",
    "                 need_sensitivities=False, \n",
    "                eval_fun=['ESS']):\n",
    "    \n",
    "    optimizer_best_fxs = []\n",
    "    optimizer_best_xs = []\n",
    "    \n",
    "    optimizer_best_fx = np.inf\n",
    "    optimizer_best_x = 0\n",
    "    \n",
    "    for j in range(50):\n",
    "        # Getting the samples of hyper-parameters for the samplers\n",
    "        optimizer_xs = opt.ask()\n",
    "        \n",
    "        # Saving the score of each sample of hyper-parameters\n",
    "        optimizer_fxs = []\n",
    "        print(j,\"start samplers run\")\n",
    "        # Evaluate performance for each hyper-parameter configuration\n",
    "        for x in optimizer_xs:\n",
    "            \n",
    "            our_x = [[x[0], x[1], x[2]], x[3], x[4], x[5]]\n",
    "\n",
    "            # Initialise function evaluations and matrix for chains\n",
    "            function_evaluations = 0 \n",
    "            chains = []\n",
    "            \n",
    "            # Return array of samples for each chain\n",
    "            for i in range(n_chains):\n",
    "\n",
    "                # Create sampler object and set hyperparameter\n",
    "                curr_x0 = sampler_x0[i]\n",
    "                mcmc = sampler(curr_x0)\n",
    "                mcmc.set_hyper_parameters(our_x)\n",
    "                i_chain = []\n",
    "                \n",
    "                # Update until we have ``chain_size`` samples\n",
    "                # Update function evaluations each time we use ask(),tell()\n",
    "                while len(i_chain) < chain_size:\n",
    "                    x = mcmc.ask()\n",
    "                    if need_sensitivities:\n",
    "                        fx, grad = problem.evaluateS1(x)\n",
    "                        sample = mcmc.tell((fx, grad))\n",
    "                    else:\n",
    "                        fx,_ = problem.evaluateS1(x)\n",
    "                        sample = mcmc.tell(fx)\n",
    "                    function_evaluations += 1\n",
    "                    if sample is not None:\n",
    "                        i_chain.append(sample)\n",
    "                \n",
    "                # Append ith chain to list of chains       \n",
    "                chains.append(i_chain)\n",
    "                \n",
    "            chains = np.array(chains, copy=True)\n",
    "            optimizer_fx = 0\n",
    "            # Calculate the score of the sampler with the given hyper-parameters\n",
    "            # Get the KL if requested\n",
    "            if 'KL' in eval_fun:\n",
    "                kl = 0\n",
    "                for chain in chains:\n",
    "                    kl += problem.kl_divergence(chain)\n",
    "                optimizer_fx = kl/len(chains)                \n",
    "            \n",
    "            elif 'KL-ITER' in eval_fun:\n",
    "                kl = 0\n",
    "                for chain in chains:\n",
    "                    kl += problem.kl_divergence(chain)\n",
    "                avg_kl = kl/len(chains)\n",
    "                avg_iteration_count = function_evaluations / len(chains)\n",
    "                optimizer_fx = avg_kl * avg_iteration_count\n",
    "            \n",
    "            # Get the ESS if requested\n",
    "            elif 'ESS' in eval_fun:\n",
    "                ess = np.zeros(chains[0].shape[1])\n",
    "                for chain in chains:\n",
    "                    ess += np.array(pints._diagnostics.effective_sample_size(chain))\n",
    "                print(ess)\n",
    "                ess /= len(chains)\n",
    "                ess = np.min(ess)\n",
    "                avg_iteration_count = function_evaluations / len(chains)\n",
    "                optimizer_fx = math.sqrt(avg_iteration_count) / ess\n",
    "                \n",
    "            optimizer_fxs.append(optimizer_fx)\n",
    "        print(j,\"end samplers run\")\n",
    "        opt.tell(optimizer_fxs)\n",
    "        print(j,\"end tell \")\n",
    "        optimizer_best_fxs.append(opt.fbest())\n",
    "        optimizer_best_xs.append(opt.xbest())\n",
    "        \n",
    "        if opt.fbest() < optimizer_best_fx:\n",
    "            optimizer_best_fx = opt.fbest()\n",
    "            optimizer_best_x = opt.xbest()\n",
    "    \n",
    "    print(optimizer_best_fx)\n",
    "    print(optimizer_best_x)\n",
    "    print()\n",
    "    \n",
    "    return optimizer_best_fxs, optimizer_best_xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosenbrock = pints.toy.RosenbrockLogPDF()\n",
    "eggshape = pints.toy.SimpleEggBoxLogPDF(2,4)\n",
    "Logistic = pints.toy.LogisticModel()\n",
    "\n",
    "problem = rosenbrock\n",
    "\n",
    "# Define the starting points of the samplers\n",
    "sampler_rosenbrock_x0 = [\n",
    "    [0,0],\n",
    "    [3,8],\n",
    "    [2,4],\n",
    "]\n",
    "\n",
    "sampler_egg_x0 = [\n",
    "    [-10,-10],\n",
    "    [0,0],\n",
    "    [10,10],\n",
    "]\n",
    "\n",
    "sampler_x0 = sampler_rosenbrock_x0\n",
    "\n",
    "# Define the starting point of the optimzer\n",
    "dummy = pints.SliceStepoutMCMC([2, 4])\n",
    "optimizer_x0 = [dummy.width()[0], dummy.width()[1], \n",
    "                    dummy.expansion_steps(), dummy.prob_overrelaxed(), dummy.bisection_steps()]\n",
    "boundary = pints.RectangularBoundaries([0,0,1,0,0],[20,20,100,1,100])\n",
    "\n",
    "sampler = pints.SliceStepoutMCMC\n",
    "\n",
    "for i in range(5):\n",
    "    cma = CMA.CMAES(optimizer_x0, boundaries=boundary)\n",
    "    fxs, xs =  CMA_on_single_var(cma, problem, sampler, \n",
    "                        sampler_x0, n_chains=3, chain_size=100, eval_fun=['ESS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2, 0.4, 50, 0, 10]\n"
     ]
    }
   ],
   "source": [
    "dummy = pints.SliceStepoutMCMC([2, 4])\n",
    "optimizer_x0 = [dummy.width()[0], dummy.width()[1], \n",
    "                    dummy.expansion_steps(), dummy.prob_overrelaxed(), dummy.bisection_steps()]\n",
    "print(optimizer_x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for the Egg Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.9179869280115049\n",
    "[ 3.61346418  2.78710331 45.84290531  0.85652318  0.5264789 ]\n",
    "\n",
    "0.9324991550798959\n",
    "[ 3.46463821  5.25609066 67.12025263  0.44649369  0.25899178]\n",
    "\n",
    "0.915696456256111\n",
    "[ 4.22828699  3.2918315  48.34857415  0.66048817  0.60508832]\n",
    "\n",
    "0.938988817824792\n",
    "[ 7.16367172  4.72366301 44.78011937  0.11087744  1.93261219]\n",
    "\n",
    "0.9176600677810929\n",
    "[ 3.91173313  3.28633446 55.26513198  0.75707419  0.26133818]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for the Rosenbrock problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.3235648912944455\n",
    "[17.48272198 16.77697123 59.29593527  0.29438362  3.94942295]\n",
    "\n",
    "2.16825776726139\n",
    "[ 7.72599655 14.37161775 62.32867035  0.36297407  0.7233022 ]\n",
    "\n",
    "1.866527310975345\n",
    "[ 5.10531175  3.71615054 23.51462788  0.78952023  1.48273688]\n",
    "\n",
    "2.2561228708422587\n",
    "[3.38122713e+00 1.49792117e+01 8.08315852e+01 6.64676628e-02\n",
    " 4.32494415e+00]\n",
    "\n",
    "1.8751304752745437\n",
    "[18.06458699  9.45095504 65.12849812  0.51251162  0.716842  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pints\n",
    "import pints.toy as toy\n",
    "import pints.plot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ExampleModel(pints.ForwardModel):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = toy.LogisticModel()\n",
    "    def simulate(self, x, times):\n",
    "        return self.model.simulate([x[0]/1000, x[1]], times)\n",
    "    def simulateS1(self, x, times):\n",
    "        values, gradient = self.model.simulateS1([x[0]/1000, x[1]], times)\n",
    "        return values, gradient\n",
    "    def n_parameters(self):\n",
    "        return 2\n",
    "\n",
    "# Then create an instance of our new model class\n",
    "model = ExampleModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some toy data\n",
    "real_parameters = [0.015*10000, 500]\n",
    "times = np.linspace(0, 1000, 1000)\n",
    "org_values = model.simulate(real_parameters, times)\n",
    "\n",
    "# Add noise\n",
    "noise = 10\n",
    "values = org_values + np.random.normal(0, noise, org_values.shape)\n",
    "real_parameters = np.array(real_parameters + [noise])\n",
    "\n",
    "# Get properties of the noise sample\n",
    "noise_sample_mean = np.mean(values - org_values)\n",
    "noise_sample_std = np.std(values - org_values)\n",
    "\n",
    "# Create an object with links to the model and time series\n",
    "problem = pints.SingleOutputProblem(model, times, values)\n",
    "\n",
    "# Create a log-likelihood function (adds an extra parameter!)\n",
    "log_likelihood = pints.GaussianLogLikelihood(problem)\n",
    "\n",
    "# Create a uniform prior over both the parameters and the new noise variable\n",
    "log_prior = pints.UniformLogPrior(\n",
    "    [0.01*10000, 400, noise * 0.1],\n",
    "    [0.02*10000, 600, noise * 100],\n",
    ")\n",
    "\n",
    "# Create a posterior log-likelihood (log(likelihood * prior))\n",
    "log_posterior = pints.LogPosterior(log_likelihood, log_prior)\n",
    "\n",
    "# Choose starting points for 3 mcmc chains\n",
    "num_chains = 3\n",
    "sampler_logistic_x0 = [\n",
    "    real_parameters * 1.01,\n",
    "    real_parameters * 0.99,\n",
    "    real_parameters * 1.01\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = log_posterior\n",
    "\n",
    "sampler_x0 = sampler_logistic_x0\n",
    "\n",
    "# Define the starting point of the optimzer\n",
    "dummy = pints.SliceStepoutMCMC([2, 4, 10])\n",
    "optimizer_x0 = [dummy.width()[0], dummy.width()[1], dummy.width()[2], \n",
    "                dummy.expansion_steps(), dummy.prob_overrelaxed(), dummy.bisection_steps()]\n",
    "\n",
    "boundary = pints.RectangularBoundaries([0,0,0,1,0,0],[7,7,7,100,1,100])\n",
    "\n",
    "sampler = pints.SliceStepoutMCMC\n",
    "\n",
    "for i in range(5):\n",
    "    cma = CMA.CMAES(optimizer_x0, boundaries=boundary)\n",
    "    fxs, xs =  CMA_on_single_var(cma, problem, sampler, \n",
    "                        sampler_x0, n_chains=3, chain_size=100, eval_fun=['ESS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2, 0.4, 1.0, 50, 0, 10]\n"
     ]
    }
   ],
   "source": [
    "dummy = pints.SliceStepoutMCMC([2, 4, 10])\n",
    "optimizer_x0 = [dummy.width()[0], dummy.width()[1], dummy.width()[2], \n",
    "                dummy.expansion_steps(), dummy.prob_overrelaxed(), dummy.bisection_steps()]\n",
    "print(optimizer_x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
