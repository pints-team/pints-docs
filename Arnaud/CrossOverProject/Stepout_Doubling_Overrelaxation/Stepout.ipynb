{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division\n",
    "from __future__ import print_function, unicode_literals\n",
    "import pints.toy as toy\n",
    "import pints\n",
    "import numpy as np\n",
    "import logging\n",
    "import math\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sys\n",
    "from numpy import inf\n",
    "import copy \n",
    "import pickle\n",
    "import time\n",
    "import CMA as CMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CMA_on_single_var(opt, \n",
    "                 problem,\n",
    "                 sampler,\n",
    "                 sampler_x0, \n",
    "                 n_chains=1,\n",
    "                 chain_size=100,\n",
    "                 need_sensitivities=False, \n",
    "                eval_fun=['ESS']):\n",
    "    \n",
    "    optimizer_best_fxs = []\n",
    "    optimizer_best_xs = []\n",
    "    \n",
    "    optimizer_best_fx = np.inf\n",
    "    optimizer_best_x = 0\n",
    "    \n",
    "    for _ in range(50):\n",
    "        \n",
    "        # Getting the samples of hyper-parameters for the samplers\n",
    "        optimizer_xs = opt.ask()\n",
    "        \n",
    "        # Saving the score of each sample of hyper-parameters\n",
    "        optimizer_fxs = []\n",
    "        \n",
    "        # Evaluate performance for each hyper-parameter configuration\n",
    "        for x in optimizer_xs:\n",
    "            \n",
    "            our_x = [[x[0], x[1], x[2]], x[3], 0, 0]\n",
    "            \n",
    "            # Initialise function evaluations and matrix for chains\n",
    "            function_evaluations = 0 \n",
    "            chains = []\n",
    "            \n",
    "            # Return array of samples for each chain\n",
    "            for i in range(n_chains):\n",
    "\n",
    "                # Create sampler object and set hyperparameter\n",
    "                curr_x0 = sampler_x0[i]\n",
    "                mcmc = sampler(curr_x0)\n",
    "                mcmc.set_hyper_parameters(our_x)\n",
    "                i_chain = []\n",
    "                \n",
    "                # Update until we have ``chain_size`` samples\n",
    "                # Update function evaluations each time we use ask(),tell()\n",
    "                while len(i_chain) < chain_size:\n",
    "                    x = mcmc.ask()\n",
    "                    if need_sensitivities:\n",
    "                        fx, grad = problem.evaluateS1(x)\n",
    "                        sample = mcmc.tell((fx, grad))\n",
    "                    else:\n",
    "                        fx, _ = problem.evaluateS1(x)\n",
    "                        sample = mcmc.tell(fx)\n",
    "                    function_evaluations += 1\n",
    "                    if sample is not None:\n",
    "                        i_chain.append(sample)\n",
    "                \n",
    "                # Append ith chain to list of chains       \n",
    "                chains.append(i_chain)\n",
    "                \n",
    "            chains = np.array(chains, copy=True)\n",
    "            optimizer_fx = 0\n",
    "            # Calculate the score of the sampler with the given hyper-parameters\n",
    "            # Get the KL if requested\n",
    "            if 'KL' in eval_fun:\n",
    "                kl = 0\n",
    "                for chain in chains:\n",
    "                    kl += problem.kl_divergence(chain)\n",
    "                optimizer_fx = kl/len(chains)                \n",
    "            \n",
    "            elif 'KL-ITER' in eval_fun:\n",
    "                kl = 0\n",
    "                for chain in chains:\n",
    "                    kl += problem.kl_divergence(chain)\n",
    "                avg_kl = kl/len(chains)\n",
    "                avg_iteration_count = function_evaluations / len(chains)\n",
    "                optimizer_fx = avg_kl * avg_iteration_count\n",
    "            \n",
    "            # Get the ESS if requested\n",
    "            elif 'ESS' in eval_fun:\n",
    "                ess = np.zeros(chains[0].shape[1])\n",
    "                for chain in chains:\n",
    "                    ess += np.array(pints._diagnostics.effective_sample_size(chain))\n",
    "                ess /= len(chains)\n",
    "                ess = np.min(ess)\n",
    "                avg_iteration_count = function_evaluations / len(chains)\n",
    "                optimizer_fx = math.sqrt(avg_iteration_count) / ess\n",
    "                \n",
    "            optimizer_fxs.append(optimizer_fx)\n",
    "        opt.tell(optimizer_fxs)\n",
    "        \n",
    "        optimizer_best_fxs.append(opt.fbest())\n",
    "        optimizer_best_xs.append(opt.xbest())\n",
    "        \n",
    "        if opt.fbest() < optimizer_best_fx:\n",
    "            optimizer_best_fx = opt.fbest()\n",
    "            optimizer_best_x = opt.xbest()\n",
    "    \n",
    "    print(optimizer_best_fx)\n",
    "    print(optimizer_best_x)\n",
    "    print()\n",
    "    \n",
    "    return optimizer_best_fxs, optimizer_best_xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9148770409186143\n",
      "[ 5.78142093  5.38034409 49.77944446]\n",
      "\n",
      "0.9186402995732336\n",
      "[ 5.03032901  6.013799   67.09158439]\n",
      "\n",
      "0.9174965939991275\n",
      "[ 6.52048241  5.46590556 50.81542717]\n",
      "\n",
      "0.915860251348425\n",
      "[ 5.15826592  5.25464768 55.50907036]\n",
      "\n",
      "0.9206269551784219\n",
      "[ 5.67126491  4.66865795 44.80952176]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rosenbrock = pints.toy.RosenbrockLogPDF()\n",
    "eggshape = pints.toy.SimpleEggBoxLogPDF(2,4)\n",
    "Logistic = pints.toy.LogisticModel()\n",
    "\n",
    "problem = eggshape\n",
    "\n",
    "# Define the starting points of the samplers\n",
    "sampler_rosenbrock_x0 = [\n",
    "    [0,0],\n",
    "    [3,8],\n",
    "    [2,4],\n",
    "]\n",
    "\n",
    "sampler_egg_x0 = [\n",
    "    [-10,-10],\n",
    "    [0,0],\n",
    "    [10,10],\n",
    "]\n",
    "\n",
    "sampler_x0 = sampler_egg_x0\n",
    "\n",
    "# Define the starting point of the optimzer\n",
    "dummy = pints.SliceStepoutMCMC([2,4])\n",
    "optimizer_x0 = [dummy.width()[0], dummy.width()[1], dummy.expansion_steps()]\n",
    "\n",
    "boundary = pints.RectangularBoundaries([0,0,1],[20,20,100])\n",
    "\n",
    "sampler = pints.SliceStepoutMCMC\n",
    "\n",
    "for i in range(5):\n",
    "    cma = CMA.CMAES(optimizer_x0, boundaries=boundary)\n",
    "    fxs, xs =  CMA_on_single_var(cma, problem, sampler, \n",
    "                        sampler_x0, n_chains=3, chain_size=100, eval_fun=['ESS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2, 0.4, 50]\n"
     ]
    }
   ],
   "source": [
    "dummy = pints.SliceStepoutMCMC([2,4])\n",
    "optimizer_x0 = [dummy.width()[0], dummy.width()[1], dummy.expansion_steps()]\n",
    "print(optimizer_x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for the Rosenbrock problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESS with 50 optimizer iterations\n",
    "2.3699577396304825\n",
    "[11.05430603  8.65556335 15.34646559]\n",
    "\n",
    "2.3540251060136512\n",
    "[10.68434538  4.13088601 91.90068149]\n",
    "\n",
    "1.617106711477928\n",
    "[13.31160578 10.86469062 45.04699239]\n",
    "\n",
    "2.357389983942719\n",
    "[ 3.66871274  7.70394962 48.84396455]\n",
    "\n",
    "2.1588561598210196\n",
    "[ 9.37848535 14.43081576 85.43210022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESS with 100 optimizer iterations\n",
    "2.0388169450864124\n",
    "[14.4180002   8.32522182 47.13485025]\n",
    "\n",
    "1.9911451981780695\n",
    "[ 3.8107873   8.67263218 50.9202088 ]\n",
    "\n",
    "1.9210559802617702\n",
    "[ 8.20768945 11.58989919 54.36013239]\n",
    "\n",
    "1.7975176335682346\n",
    "[ 9.26843484  9.649202   48.66623769]\n",
    "\n",
    "1.9065569362301396\n",
    "[14.63821681  8.11957799 50.73190656]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for the Egg Problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.9148770409186143\n",
    "[ 5.78142093  5.38034409 49.77944446]\n",
    "\n",
    "0.9186402995732336\n",
    "[ 5.03032901  6.013799   67.09158439]\n",
    "\n",
    "0.9174965939991275\n",
    "[ 6.52048241  5.46590556 50.81542717]\n",
    "\n",
    "0.915860251348425\n",
    "[ 5.15826592  5.25464768 55.50907036]\n",
    "\n",
    "0.9206269551784219\n",
    "[ 5.67126491  4.66865795 44.80952176]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pints\n",
    "import pints.toy as toy\n",
    "import pints.plot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ExampleModel(pints.ForwardModel):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = toy.LogisticModel()\n",
    "    def simulate(self, x, times):\n",
    "        return self.model.simulate([x[0]/1000, x[1]], times)\n",
    "    def simulateS1(self, x, times):\n",
    "        values, gradient = self.model.simulateS1([x[0]/1000, x[1]], times)\n",
    "        return values, gradient\n",
    "    def n_parameters(self):\n",
    "        return 2\n",
    "\n",
    "# Then create an instance of our new model class\n",
    "model = ExampleModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some toy data\n",
    "real_parameters = [0.015*10000, 500]\n",
    "times = np.linspace(0, 1000, 1000)\n",
    "org_values = model.simulate(real_parameters, times)\n",
    "\n",
    "# Add noise\n",
    "noise = 10\n",
    "values = org_values + np.random.normal(0, noise, org_values.shape)\n",
    "real_parameters = np.array(real_parameters + [noise])\n",
    "\n",
    "# Get properties of the noise sample\n",
    "noise_sample_mean = np.mean(values - org_values)\n",
    "noise_sample_std = np.std(values - org_values)\n",
    "\n",
    "# Create an object with links to the model and time series\n",
    "problem = pints.SingleOutputProblem(model, times, values)\n",
    "\n",
    "# Create a log-likelihood function (adds an extra parameter!)\n",
    "log_likelihood = pints.GaussianLogLikelihood(problem)\n",
    "\n",
    "# Create a uniform prior over both the parameters and the new noise variable\n",
    "log_prior = pints.UniformLogPrior(\n",
    "    [0.01*10000, 400, noise * 0.1],\n",
    "    [0.02*10000, 600, noise * 100],\n",
    ")\n",
    "\n",
    "# Create a posterior log-likelihood (log(likelihood * prior))\n",
    "log_posterior = pints.LogPosterior(log_likelihood, log_prior)\n",
    "\n",
    "# Choose starting points for 3 mcmc chains\n",
    "num_chains = 3\n",
    "sampler_logistic_x0 = [\n",
    "    real_parameters * 1.01,\n",
    "    real_parameters * 0.99,\n",
    "    real_parameters * 1.01\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naunauyoh/anaconda3/lib/python3.7/site-packages/pints/_log_likelihoods.py:476: RuntimeWarning: invalid value encountered in log\n",
      "  - np.sum(error**2, axis=0) / (2 * sigma**2))\n",
      "/home/naunauyoh/anaconda3/lib/python3.7/site-packages/pints/toy/_logistic_model.py:77: RuntimeWarning: overflow encountered in square\n",
      "  dvalues_dp[:, 0] = k * times * c * exp / (c * exp + 1)**2\n",
      "/home/naunauyoh/anaconda3/lib/python3.7/site-packages/pints/toy/_logistic_model.py:79: RuntimeWarning: overflow encountered in square\n",
      "  (self._p0 * (c * exp + 1)**2) + 1 / (c * exp + 1)\n",
      "/home/naunauyoh/anaconda3/lib/python3.7/site-packages/pints/toy/_logistic_model.py:79: RuntimeWarning: overflow encountered in multiply\n",
      "  (self._p0 * (c * exp + 1)**2) + 1 / (c * exp + 1)\n",
      "/home/naunauyoh/anaconda3/lib/python3.7/site-packages/pints/toy/_logistic_model.py:73: RuntimeWarning: overflow encountered in multiply\n",
      "  values = k / (1 + c * exp)\n",
      "/home/naunauyoh/anaconda3/lib/python3.7/site-packages/pints/toy/_logistic_model.py:77: RuntimeWarning: overflow encountered in multiply\n",
      "  dvalues_dp[:, 0] = k * times * c * exp / (c * exp + 1)**2\n",
      "/home/naunauyoh/anaconda3/lib/python3.7/site-packages/pints/toy/_logistic_model.py:77: RuntimeWarning: invalid value encountered in true_divide\n",
      "  dvalues_dp[:, 0] = k * times * c * exp / (c * exp + 1)**2\n",
      "/home/naunauyoh/anaconda3/lib/python3.7/site-packages/pints/toy/_logistic_model.py:78: RuntimeWarning: overflow encountered in multiply\n",
      "  dvalues_dp[:, 1] = -k * exp / \\\n",
      "/home/naunauyoh/anaconda3/lib/python3.7/site-packages/pints/toy/_logistic_model.py:79: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (self._p0 * (c * exp + 1)**2) + 1 / (c * exp + 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6219432789095927\n",
      "[ 9.01644044  7.34822443 19.32858128 12.03208208]\n",
      "\n",
      "1.6182562230655584\n",
      "[ 8.91870117  2.33349609 10.76036024 15.54291153]\n",
      "\n",
      "1.6095915822776565\n",
      "[17.61793998  9.04269958  2.91262978 10.1872789 ]\n",
      "\n",
      "1.5996716791890495\n",
      "[ 4.54942653  2.8307395   3.23276806 14.28846185]\n",
      "\n",
      "1.624845442136124\n",
      "[ 5.52388364  9.47853088  3.30059324 10.02181839]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "problem = log_posterior\n",
    "\n",
    "sampler_x0 = sampler_logistic_x0\n",
    "\n",
    "# Define the starting point of the optimzer\n",
    "dummy = pints.SliceDoublingMCMC([2, 4, 10])\n",
    "optimizer_x0 = [dummy.width()[0], dummy.width()[1], dummy.width()[2], dummy.expansion_steps()]\n",
    "\n",
    "boundary = pints.RectangularBoundaries([0,0,0,1],[20,20,20,15])\n",
    "\n",
    "sampler = pints.SliceDoublingMCMC\n",
    "\n",
    "for i in range(5):\n",
    "    cma = CMA.CMAES(optimizer_x0, boundaries=boundary)\n",
    "    fxs, xs =  CMA_on_single_var(cma, problem, sampler, \n",
    "                        sampler_x0, n_chains=3, chain_size=100, eval_fun=['ESS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2, 0.4, 1.0, 10]\n"
     ]
    }
   ],
   "source": [
    "dummy = pints.SliceDoublingMCMC([2, 4, 10])\n",
    "optimizer_x0 = [dummy.width()[0], dummy.width()[1], dummy.width()[2], dummy.expansion_steps()]\n",
    "print(optimizer_x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.6219432789095927\n",
    "[ 9.01644044  7.34822443 19.32858128 12.03208208]\n",
    "\n",
    "1.6182562230655584\n",
    "[ 8.91870117  2.33349609 10.76036024 15.54291153]\n",
    "\n",
    "1.6095915822776565\n",
    "[17.61793998  9.04269958  2.91262978 10.1872789 ]\n",
    "\n",
    "1.5996716791890495\n",
    "[ 4.54942653  2.8307395   3.23276806 14.28846185]\n",
    "\n",
    "1.624845442136124\n",
    "[ 5.52388364  9.47853088  3.30059324 10.02181839]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
