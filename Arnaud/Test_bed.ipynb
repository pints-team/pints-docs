{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division\n",
    "from __future__ import print_function, unicode_literals\n",
    "import pints.toy as toy\n",
    "import pints\n",
    "import numpy as np\n",
    "import logging\n",
    "import math\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from numpy import inf\n",
    "\n",
    "model_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGISTIC MODEL # \n",
    "log_dict = dict()\n",
    "\n",
    "log_dict['name'] = \"Logistic model\"\n",
    "log_dict['model'] = toy.LogisticModel()\n",
    "\n",
    "log_dict['real_parameters'] = [0.5, 500]\n",
    "log_dict['times']  = log_dict['model'].suggested_times()\n",
    "\n",
    "log_dict['boundaries'] = pints.RectangularBoundaries([0, 200], [1, 1000])\n",
    "\n",
    "# Choose an initial position\n",
    "log_dict['x0'] = [0.2, 420]\n",
    "\n",
    "model_dict['Logistic'] = log_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beeler Reuter Act Pot #\n",
    "BR_dict = dict()\n",
    "\n",
    "BR_dict['name'] = \"Beeler Reuter Action Potential model\" \n",
    "BR_dict['model'] = toy.ActionPotentialModel()\n",
    "\n",
    "BR_dict['real_parameters'] = BR_dict['model'].suggested_parameters() # 4.0, 0.003, 0.09, 0.35, 0.8\n",
    "BR_dict['times'] = BR_dict['model'].suggested_times()\n",
    "\n",
    "BR_dict['boudaries'] = pints.RectangularBoundaries([-20, -2, -2, -2, -2], [20, 2, 2, 2, 2])\n",
    "\n",
    "BR_dict['x0'] = np.log([3.0, 0.001, 0.06, 0.29, 0.6])\n",
    "\n",
    "model_dict['Beeler_Reuter'] = BR_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HH_IK #\n",
    "HH_dict = dict()\n",
    "\n",
    "HH_dict['name'] = \"Hodgkin Huxley IK model\"\n",
    "HH_dict['model'] = toy.HodgkinHuxleyIKModel()\n",
    "\n",
    "HH_dict['real_parameters'] = HH_dict['model'].suggested_parameters() # 0.01, 10, 10, 0.125, 80\n",
    "HH_dict['times'] = HH_dict['model'].suggested_times()\n",
    "\n",
    "HH_dict['boudaries'] = pints.RectangularBoundaries([-2, -200, -200, -2, -200], [2, 200, 200, 2, 200])\n",
    "\n",
    "HH_dict['x0'] = 0.001, 5, 20, 0.335, 37\n",
    "\n",
    "model_dict['Hodgkin_Huxley'] = HH_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HES_1 #\n",
    "H1_dict = dict()\n",
    "\n",
    "H1_dict['name'] = \"HES1 Michaelis-Menten\"\n",
    "H1_dict['model'] = toy.Hes1Model()\n",
    "\n",
    "H1_dict['real_parameters'] = H1_dict['model'].suggested_parameters() #[2.4, 0.025, 0.11, 6.9]\n",
    "H1_dict['times'] = H1_dict['model'].suggested_times()\n",
    "\n",
    "H1_dict['boudaries'] = pints.RectangularBoundaries([-20, -2, -2, -200], [20, 2, 2, 200])\n",
    "\n",
    "H1_dict['x0'] = [7, 0.35, 0.9, 20]\n",
    "\n",
    "model_dict['HES Michaelis-Menten'] = H1_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GoodwinOscillatorModel #\n",
    "GOM_dict = dict()\n",
    "\n",
    "GOM_dict['name'] = \"Goodwin Oscillator Model\"\n",
    "GOM_dict['model'] = toy.GoodwinOscillatorModel()\n",
    "\n",
    "GOM_dict['real_parameters'] = GOM_dict['model'].suggested_parameters() #[2, 4, 0.12, 0.08, 0.1]\n",
    "GOM_dict['times'] = GOM_dict['model'].suggested_times()\n",
    "\n",
    "GOM_dict['boudaries'] = pints.RectangularBoundaries([-20, -200, -2, -2, -2], [20, 200, 2, 2, 2])\n",
    "\n",
    "GOM_dict['x0'] = [10, 15, 0.7, 0.40, 0.9]\n",
    "\n",
    "model_dict['Three-state Goodwin oscillator'] = GOM_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently testing on Three-state Goodwin oscillator\n",
      "Starting CMA-NOT\n",
      "Average best score for CMA-NOT after 5 trials 92.75621048302757\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CMA\n",
      "Average best score for CMA after 5 trials 92.78921026751865\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting SNES\n"
     ]
    }
   ],
   "source": [
    "for key, value in model_dict.items():\n",
    "    \n",
    "    print(\"Currently testing on\", key)\n",
    "    \n",
    "    x0 = value['x0']\n",
    "\n",
    "    xnes = pints.XNES(x0)\n",
    "    snes = pints.SNES(x0)\n",
    "    cma_not = pints.CMAES(x0)\n",
    "    cma = CMAES(x0)\n",
    "    sgd = SGD(x0)\n",
    "\n",
    "    # (\"SGD\", sgd)\n",
    "    opts = [ (\"CMA-NOT\",cma_not), (\"CMA\",cma), (\"SNES\",snes) , (\"XNES\",xnes)]\n",
    "\n",
    "    model_testbed(value['model'], value['real_parameters'], value['times'], opts)\n",
    "    \n",
    "    print(\"Done with\", key)\n",
    "    print('############################################')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_testbed(model,\n",
    "                  real_parameters,\n",
    "                  times,\n",
    "                  optimizers, \n",
    "                  iterations=100,\n",
    "                  tries=5):\n",
    "    \n",
    "    \n",
    "    #Generate the values\n",
    "    try:\n",
    "        values, _ = model.simulateS1(real_parameters, times)\n",
    "    except:\n",
    "        values = model.simulate(real_parameters, times)\n",
    "        \n",
    "    # Add noise\n",
    "    values += np.random.normal(0, 10, values.shape)\n",
    "    # Create an object with links to the model and time series\n",
    "    try:\n",
    "        my_problem = pints.SingleOutputProblem(model, times, values)\n",
    "    except:\n",
    "        my_problem = pints.MultiOutputProblem(model, times, values)\n",
    "    \n",
    "    # Select a score function\n",
    "    score = pints.MeanSquaredError(my_problem)\n",
    "    \n",
    "    for name, opt in optimizers:\n",
    "        print(\"Starting\", name)\n",
    "        avg_best_fxs = []\n",
    "        avg_best_xs = []\n",
    "        for j in range(tries):    \n",
    "            best_fxs = []\n",
    "            best_xs = []\n",
    "            #try:\n",
    "            for i in range(iterations):\n",
    "                xs = opt.ask()\n",
    "                # Save the values for the plot \n",
    "                if (i) % 5 == 0:\n",
    "                    best_xs.append(opt.xbest())\n",
    "                # Evaluate the scores\n",
    "                fxs = [score(x) for x in xs]\n",
    "                opt.tell(fxs)\n",
    "                # Store the best score\n",
    "                best_fxs.append(opt.fbest())\n",
    "            avg_best_fxs.append(best_fxs)\n",
    "            #except Exception as e:\n",
    "            #   print('One run failed: ', e)\n",
    "        avg_best_fxs = np.average(avg_best_fxs, 0)\n",
    "\n",
    "        \n",
    "        # Show how the score converges\n",
    "        print(\"Average best score for\", name, \"after\", tries , \"trials\", avg_best_fxs[-1])\n",
    "        axes = plt.gca()\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Score')\n",
    "        plt.plot(avg_best_fxs)\n",
    "        plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMAES(pints.PopulationBasedOptimiser):\n",
    "    \"\"\"\n",
    "    Finds the best parameters using the CMA-ES method described in [1, 2].\n",
    "    \n",
    "    CMA-ES stands for Covariance Matrix Adaptation Evolution Strategy, and is\n",
    "    designed for non-linear derivative-free optimization problems.\n",
    "    \n",
    "    *Extends:* :class:`PopulationBasedOptimiser`\n",
    "    \n",
    "    [1] https://arxiv.org/pdf/1604.00772.pdf\n",
    "    \n",
    "    [2] Hansen, Mueller, Koumoutsakos (2006) Reducing the time complexity of\n",
    "    the derandomized evolution strategy with covariance matrix adaptation\n",
    "    (CMA-ES).\n",
    "    \n",
    "    Important note: The parameter parent_pop_size is the mu in the papers. It represents the size of a parent population \n",
    "        used to update our paramters. \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x0, sigma0=0.1, boundaries=None):\n",
    "        super(CMAES, self).__init__(x0, sigma0, boundaries)\n",
    "\n",
    "        # Set initial state\n",
    "        self._running = False\n",
    "        self._ready_for_tell = False\n",
    "\n",
    "        # Best solution found\n",
    "        self._xbest = pints.vector(x0)\n",
    "        self._fbest = float('inf')\n",
    "        \n",
    "        # Python logger\n",
    "        self._logger = logging.getLogger(__name__)\n",
    "        \n",
    "        self._printing = False\n",
    "        \n",
    "        self._counter = 0\n",
    "            \n",
    "    def set_print(self, v):\n",
    "        self._printing = v\n",
    "    \n",
    "    def ask(self):\n",
    "        \"\"\" See :meth:`Optimiser.ask()`. \"\"\"\n",
    "        # Initialise on first call\n",
    "        if not self._running:\n",
    "            self._initialise()\n",
    "\n",
    "        # Ready for tell now\n",
    "        self._ready_for_tell = True\n",
    "\n",
    "        # Create new samples\n",
    "        self._zs = np.array([np.random.multivariate_normal([0] * self._n_parameters, np.identity(self._n_parameters)) \n",
    "                   for _ in range(self._population_size)])\n",
    "        \n",
    "        self._ys = np.array([self._B.dot(self._D).dot(z) for z in self._zs])\n",
    "        \n",
    "        self._user_xs = self._xs = np.array([self._x0 + self._sigma0 * self._ys[i] \n",
    "                                             for i in range(self._population_size)])\n",
    "        \n",
    "        # Set as read-only and return\n",
    "        self._user_xs.setflags(write=False)\n",
    "        return self._user_xs\n",
    "\n",
    "    def fbest(self):\n",
    "        \"\"\" See :meth:`Optimiser.fbest()`. \"\"\"\n",
    "        if not self._running:\n",
    "            return float('inf')\n",
    "        return self._fbest\n",
    "\n",
    "    def _initialise(self):\n",
    "        \"\"\"\n",
    "        Initialises the optimiser for the first iteration.\n",
    "        \"\"\"\n",
    "        assert(not self._running)\n",
    "\n",
    "        # Set boundaries, or use manual boundary checking\n",
    "        self._manual_boundaries = False\n",
    "        if isinstance(self._boundaries, pints.RectangularBoundaries):\n",
    "            options.set(\n",
    "                'bounds',\n",
    "                [list(self._boundaries._lower), list(self._boundaries._upper)]\n",
    "            )\n",
    "        elif self._boundaries is not None:\n",
    "            self._manual_boundaries = True\n",
    "\n",
    "\n",
    "        # CMA-ES wants a single standard deviation as input, use the smallest\n",
    "        # in the vector (if the user passed in a scalar, this will be the\n",
    "        # value used). THIS IS ALSO THE STEP SIZE\n",
    "        self._sigma0 = np.min(self._sigma0)\n",
    "        \n",
    "        # Eigenvectors\n",
    "        self._B = np.identity(self._n_parameters)\n",
    "        # SquareRoot of Diagnonal of EigenValues\n",
    "        self._D = np.identity(self._n_parameters)\n",
    "        # Cov-matrix (also identity)\n",
    "        self._C = self._B.dot(self._D).dot(self._D.T).dot(self._B.T)\n",
    "        \n",
    "        # Parent generation population size\n",
    "        # Not sure if the limitation to dim is good\n",
    "        # This limitation is supposed to prevent a mistake in the update of the Covariance\n",
    "        # matrix (C) with the rank mu update \n",
    "        self._parent_pop_size = self._population_size // 2 \n",
    "                                    \n",
    "        # Weights, all set equal for the moment (not sure how they are actually defined)\n",
    "        # Sum of all positive weights should be 1\n",
    "        self._W = [ math.log((self._population_size +1)/2.) - math.log(i) for i in range(1,self._population_size+1)]\n",
    "        \n",
    "        # Inverse of the Sum of the first parent weights squared (variance effective selection mass)                       \n",
    "        self._muEff = np.sum(self._W[:self._parent_pop_size])**2 / np.sum(np.square(self._W[:self._parent_pop_size]))  \n",
    "\n",
    "        # Inverse of the Sum of the last weights squared (variance effective selection mass)                       \n",
    "        self._muEffMinus = np.sum(self._W[self._parent_pop_size:])**2 / np.sum(np.square(self._W[self._parent_pop_size:]))  \n",
    "        \n",
    "        # cumulation, evolution paths, used to update Cov matrix and sigma)\n",
    "        self._pc = np.zeros(self._n_parameters)\n",
    "        self._psig = np.zeros(self._n_parameters)\n",
    "\n",
    "        # learning rate for the mean\n",
    "        self._cm = 1\n",
    "        \n",
    "        # Decay rate of the evolution path for C\n",
    "        self._ccov = (4 + self._muEff/self._n_parameters ) / (self._n_parameters + 4 + 2*self._muEff/self._n_parameters )\n",
    "        \n",
    "        # Decay rate of the evolution path for sigma\n",
    "        self._csig = (2 + self._muEff) / (self._n_parameters + 5 + self._muEff)\n",
    "\n",
    "        # See rank-1 vs rank-mu updates \n",
    "        # Learning rate for rank-1 update\n",
    "        self._c1 = 2 / ((self._n_parameters + 1.3)**2 + self._muEff)\n",
    "        \n",
    "        # Learning rate for rank-mu update\n",
    "        self._cmu = min( 2 * (self._muEff - 2 + 1 / self._muEff) / ((self._n_parameters + 2)**2 + self._muEff)\n",
    "                        , 1 - self._c1)\n",
    "        \n",
    "        # Damping of the step-size (sigma0) update\n",
    "        self._dsig = 1 + 2 * max(0,math.sqrt((self._muEff - 1) / (self._n_parameters + 1)) -1) + self._csig\n",
    "                \n",
    "            \n",
    "        # Parameters from the Table 1 of [1]\n",
    "        alphaMu = 1 + self._c1/ self._cmu \n",
    "        alphaMuEff = 1 + 2*self._muEffMinus/(self._muEff + 2)\n",
    "        alphaPosDef = (1 - self._c1 - self._cmu)/ (self._n_parameters * self._cmu)\n",
    "        \n",
    "        # Rescaling the weights\n",
    "        sum_pos = sum([ self._W[i] if self._W[i] > 0 else 0 for i in range(self._population_size)])\n",
    "        sum_neg = sum([ self._W[i] if self._W[i] < 0 else 0 for i in range(self._population_size)])\n",
    "        \n",
    "        self._W = [ self._W[i] / sum_pos  \n",
    "                   if self._W[i] >= 0\n",
    "                   else self._W[i] * min(alphaMu, alphaMuEff, alphaPosDef)/-sum_neg\n",
    "                  for i in range(self._population_size)]\n",
    "\n",
    "        if self._printing:\n",
    "            print(\"parents weights \", self._W[:self._parent_pop_size])\n",
    "            print(\"other weights\", self._W[self._parent_pop_size:])\n",
    "            print(\"other weights\", sum(self._W[self._parent_pop_size:]), \"vs alphamu\", alphaMu)\n",
    "            print(\"c1\", self._c1)\n",
    "            print(\"cmu\", self._cmu)\n",
    "            print(\"ccov\", self._ccov)\n",
    "            print(\"csig\", self._csig)\n",
    "       \n",
    "        # CMAES always seeds np.random, whether you ask it too or not, so to\n",
    "        # get consistent debugging output, we should always pass in a seed.\n",
    "        # Instead of using a fixed number (which would be bad), we can use a\n",
    "        # randomly generated number: This will ensure pseudo-randomness, but\n",
    "        # produce consistent results if np.random has been seeded before\n",
    "        # calling.\n",
    "        self._seed = 2**31\n",
    "\n",
    "        # Update optimiser state\n",
    "        self._running = True\n",
    "\n",
    "    def name(self):\n",
    "        \"\"\" See :meth:`Optimiser.name()`. \"\"\"\n",
    "        return 'Covariance Matrix Adaptation Evolution Strategy (CMA-ES)'\n",
    "\n",
    "    def running(self):\n",
    "        \"\"\" See :meth:`Optimiser.running()`. \"\"\"\n",
    "        return self._running\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\" See :meth:`Optimiser.stop()`. \"\"\"\n",
    "        if not self._running:\n",
    "            return False\n",
    "        stop = self._es.stop()\n",
    "        if stop:\n",
    "            if 'tolconditioncov' in stop:    # pragma: no cover\n",
    "                return 'Ill-conditioned covariance matrix.'\n",
    "\n",
    "            self._logger.debug(\n",
    "                'CMA-ES stopping condition(s) reached: ' +\n",
    "                '; '.join([str(x) for x in stop.keys()]))\n",
    "        return False\n",
    "    \n",
    "    ## TODO\n",
    "    def _stop():\n",
    "        return \n",
    "        \n",
    "\n",
    "    def _suggested_population_size(self):\n",
    "        \"\"\" See :meth:`Optimiser._suggested_population_size(). \"\"\"\n",
    "        return 4 + int(3 * np.log(self._n_parameters))\n",
    "\n",
    "    def tell(self, fx):\n",
    "        \"\"\" See :meth:`Optimiser.tell()`. \"\"\"\n",
    "        if not self._ready_for_tell:\n",
    "            raise Exception('ask() not called before tell()')\n",
    "        self._ready_for_tell = False\n",
    "        \n",
    "        self._counter += 1\n",
    "        \n",
    "        fx[ fx == inf ] = sys.maxsize\n",
    "                \n",
    "        # Get the best xs according to the fx results\n",
    "        order = np.argsort(fx)\n",
    "        xs_bests = np.array(self._xs[order])\n",
    "        zs_bests = np.array(self._zs[order])\n",
    "        ys_bests = np.array(self._ys[order]) # = np.array((xs_bests - self._x0) / self._sigma0)\n",
    "        \n",
    "        # Update the mean\n",
    "        old_x0 = self._x0\n",
    "        self._x0 = self._x0 + self._cm * np.sum(np.multiply((xs_bests[:self._parent_pop_size] - self._x0).T,\n",
    "                                                            self._W[:self._parent_pop_size]).T , 0)\n",
    "        \n",
    "        if self._printing:\n",
    "            print(\"Weights\", self._W)\n",
    "            print(\"Mean\", self._x0)\n",
    "            print(\"Ordered xs\", xs_bests)\n",
    "            print(\"Ordered zs\", zs_bests)\n",
    "            print(\"Ordered ys\", ys_bests)\n",
    "        \n",
    "        # Normalizing constants for the evolution path udpate\n",
    "        norm_cst_sig = math.sqrt(self._csig * (2 - self._csig) * self._muEff)\n",
    "        norm_cst_c = math.sqrt(self._ccov * (2 - self._ccov) * self._muEff)\n",
    "\n",
    "        \n",
    "        # Get the weighted means of y and z\n",
    "        zmeans = np.sum(np.multiply(zs_bests[:self._parent_pop_size].T,self._W[:self._parent_pop_size]).T,0)\n",
    "        ymeans = np.sum(np.multiply(ys_bests[:self._parent_pop_size].T,self._W[:self._parent_pop_size]).T,0)\n",
    "        \n",
    "        # Evolution path of sigma (the step size)\n",
    "        # Note that self._B.dot(zmeans) = self._B.dot(np.linalg.inv(self._D)).dot(self._B.T).dot(ymeans)\n",
    "        self._psig = (1 - self._csig) * self._psig + norm_cst_sig * self._B.dot(zmeans)\n",
    "        \n",
    "        # Heaviside function helps to stall the of pc if norm ||psig|| is too large. \n",
    "        # This helps to prevent too fast increases in the axes of C when the step size are too small. \n",
    "        exp_size_N0I = (math.sqrt(2) * math.gamma((self._n_parameters + 1)/2) / math.gamma(self._n_parameters/2))\n",
    "        \n",
    "        h_sig = 1 if np.linalg.norm(self._psig)/ math.sqrt(1-(1-self._csig)**(2 * (self._counter + 1))) < \\\n",
    "                        (1.4 + 2/(self._n_parameters+1)) * exp_size_N0I else 0\n",
    "        \n",
    "        delta_sig = (1 - h_sig) * self._ccov * (2 - self._ccov)\n",
    "        \n",
    "        #Evolution path for the rank-1 update\n",
    "        self._pc = (1 - self._ccov) * self._pc + h_sig * norm_cst_c * ymeans\n",
    "\n",
    "        if self._printing and False:\n",
    "            print(\"BD-1B\", self._B.dot(np.linalg.inv(self._D)).dot(self._B.T))\n",
    "            print(\"C-1/2\", np.sqrt(np.linalg.inv(self._C)))\n",
    "        \n",
    "        # Weight changes taken from the tutorial (no explanation is given for the change)\n",
    "        # these weights are used for the rank mu update only \n",
    "        # NOT USED \n",
    "        temp_weights = [self._W[i] if self._W[i]>=0 \n",
    "                        else self._W[i] * self._n_parameters / (np.linalg.norm(self._B * ys_bests[i])**2) \n",
    "                        for i in range(self._population_size)]\n",
    "        \n",
    "        \n",
    "        # Update the Covariance matrix:\n",
    "        # First carry on some of the previous value\n",
    "        # Add the rank 1 update using the Evolution path\n",
    "        # Add the rank-mu update \n",
    "        rank1 = self._c1 * np.outer(self._pc,self._pc)\n",
    "        rankMu = self._cmu * np.sum(np.multiply(np.array([ np.outer(y,y) for y in ys_bests]).T,\n",
    "                                                            self._W).T, 0)\n",
    "        \n",
    "        if self._printing and False:\n",
    "            print(\"OLD COV\", self._C)\n",
    "            print(\"RANK 1\", rank1)\n",
    "            print(\"RANK MU\", rankMu)\n",
    "            print(\"EVO PATH rank 1\", self._pc)\n",
    "            print(\"ONLY rank1 COV\", (1 - self._c1) * self._C + rank1)\n",
    "            print(\"ONLY rankmu COV\", (1 - self._cmu * sum(self._W)) * self._C+ rankMu)\n",
    "            \n",
    "        \n",
    "        self._C = (1 + delta_sig * self._c1 - self._c1 - self._cmu * sum(self._W)) * self._C + rank1 + rankMu\n",
    "                  \n",
    "        # Update of the step size\n",
    "        # Here we are simply looking at the ratio of the length of the evolution path \n",
    "        # vs its expected lenght ( E|Gaussian(0,I)|)\n",
    "        # We use the difference of the ratio with 1 and scale using the learning rate and the damping parameters.\n",
    "        exp_size_N0I = (math.sqrt(2) * math.gamma((self._n_parameters + 1)/2) / math.gamma(self._n_parameters/2))\n",
    "            \n",
    "        self._sigma0 = self._sigma0 * math.exp(self._csig / self._dsig * \n",
    "                            (np.linalg.norm(self._psig) / exp_size_N0I - 1))\n",
    "        \n",
    "        if self._printing and False:\n",
    "            print(\"EVO PATH sigma\", self._psig)\n",
    "            print(\"Step size\", self._sigma0)\n",
    "        \n",
    "      \n",
    "        # Update B and D\n",
    "        self._C = np.triu(self._C) + np.triu(self._C,1).T\n",
    "        [eigenvals,self._B] = np.linalg.eigh(self._C)\n",
    "        self._D = np.sqrt(np.diag(eigenvals))\n",
    "        \n",
    "        if self._printing:\n",
    "            print(\"C\", self._C)\n",
    "            print(\"BD**2B.T\", self._B.dot(self._D).dot(self._D).dot(self._B.T))\n",
    "            print(\"B or EIGENVECTORS\", self._B)\n",
    "            print(\"EIGENVALUES\", eigenvals)\n",
    "            print(\"D\", self._D)\n",
    "            \n",
    "        if self._fbest > fx[order[0]]:\n",
    "            self._fbest = fx[order[0]]\n",
    "            self._xbest = xs_bests[0]\n",
    "    \n",
    "        if self._printing:\n",
    "            print()\n",
    "            print(\"#########################\")\n",
    "            print()\n",
    "    \n",
    "    \n",
    "    def cov(self):\n",
    "        return self._C\n",
    "    \n",
    "    def xbest(self):\n",
    "        \"\"\" See :meth:`Optimiser.xbest()`. \"\"\"\n",
    "        if self._running:\n",
    "            return np.array(self._xbest, copy=True)\n",
    "        return np.array([float('inf')] * self._n_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD(pints.PopulationBasedOptimiser):\n",
    "    \"\"\"\n",
    "    Finds the best parameters using the SGD method. \n",
    "    SGD stands for Stochastic Gradient Descent.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x0, sigma0=None, boundaries=None, \n",
    "                     use_exact_grad=False):\n",
    "        super(SGD, self).__init__(x0, sigma0, boundaries)\n",
    "\n",
    "        # Set initial state\n",
    "        self._running = False\n",
    "        self._ready_for_tell = False\n",
    "\n",
    "        # Best solution found\n",
    "        self._xbest = pints.vector(x0)\n",
    "        self._fbest = float('inf')\n",
    "\n",
    "        # Python logger\n",
    "        self._logger = logging.getLogger(__name__)\n",
    "        self._population_size = 20\n",
    "        \n",
    "        # Do we use the approximate gradients?\n",
    "        self._use_exact_grad = use_exact_grad\n",
    "\n",
    "    def ask(self):\n",
    "        \"\"\" See :meth:`Optimiser.ask()`. \"\"\"\n",
    "        # Initialise on first call\n",
    "        if not self._running:\n",
    "            self._initialise()\n",
    "\n",
    "        # Ready for tell now\n",
    "        self._ready_for_tell = True\n",
    "      \n",
    "        # New sample with all but one parameter fixed\n",
    "        # Issue, our fbest and xbest are meaning less because we are not exploring on all \n",
    "        # params at the same time.. (isn't a huge issue however)\n",
    "        self._xs = np.array([]).reshape(0,2)\n",
    "        self._zs = np.array([np.random.normal(1, 0.005) \n",
    "                             for i in range(self._population_size)])\n",
    "        for i in range(self._n_parameters):\n",
    "            # Modify only for one parameter\n",
    "            temp = np.full((self._population_size, self._n_parameters), self._weights)\n",
    "            temp[:,i] *= self._zs\n",
    "            self._xs = np.vstack([self._xs, temp])\n",
    "        \n",
    "        if self._manual_boundaries:\n",
    "            # Manual boundaries? Then pass only xs that are within bounds\n",
    "            self._user_ids = np.nonzero(\n",
    "                [self._boundaries.check(x) for x in self._xs])\n",
    "            self._user_xs = self._xs[self._user_ids]\n",
    "            if len(self._user_xs) == 0:     # pragma: no cover\n",
    "                self._logger.warning(\n",
    "                    'All points requested by SGD are outside the boundaries.')\n",
    "        else:\n",
    "            self._user_xs = self._xs\n",
    "\n",
    "        # Set as read-only and return\n",
    "        self._user_xs.setflags(write=False)\n",
    "        return self._user_xs\n",
    "\n",
    "    def fbest(self):\n",
    "        \"\"\" See :meth:`Optimiser.fbest()`. \"\"\"\n",
    "        return self._fbest\n",
    "\n",
    "    def _initialise(self):\n",
    "        \"\"\"\n",
    "        Initialises the optimiser for the first iteration.\n",
    "        \"\"\"\n",
    "        assert(not self._running)\n",
    "        \n",
    "        #TODO, make change possible\n",
    "        self._step_size = 0.001\n",
    "        \n",
    "        self._manual_boundaries = False\n",
    "        self._boundary_transform = None\n",
    "        if isinstance(self._boundaries, pints.RectangularBoundaries):\n",
    "            self._boundary_transform = pints.TriangleWaveTransform(\n",
    "                self._boundaries)\n",
    "        elif self._boundaries is not None:\n",
    "            self._manual_boundaries = True\n",
    "\n",
    "        self._weights = np.array(self._x0)\n",
    "        \n",
    "        # Update optimiser state\n",
    "        self._running = True\n",
    "\n",
    "    def name(self):\n",
    "        \"\"\" See :meth:`Optimiser.name()`. \"\"\"\n",
    "        return 'Constant Step Stochastic Gradient Descent (SGD)'\n",
    "\n",
    "    def running(self):\n",
    "        \"\"\" See :meth:`Optimiser.running()`. \"\"\"\n",
    "        return self._running\n",
    "\n",
    "    def set_step_size(self, step, scalar=True):\n",
    "        self._step_size = step\n",
    "        \n",
    "    def gradient(self):\n",
    "        return self._gradient\n",
    "\n",
    "    def _suggested_population_size(self):\n",
    "        \"\"\" See :meth:`Optimiser._suggested_population_size(). \"\"\"\n",
    "        return 4 + int(3 * np.log(self._n_parameters))\n",
    "\n",
    "    def tell(self, fx):\n",
    "        \"\"\" See :meth:`Optimiser.tell()`. \"\"\"\n",
    "        if not self._ready_for_tell:\n",
    "            raise Exception('ask() not called before tell()')\n",
    "        self._ready_for_tell = False\n",
    "\n",
    "        \n",
    "        if self._manual_boundaries and len(fx) < self._population_size:\n",
    "            user_fx = fx\n",
    "            fx = np.ones((self._population_size, )) * float('inf')\n",
    "            fx[self._user_ids] = user_fx\n",
    "        \n",
    "        \n",
    "        if self._use_exact_grad:\n",
    "            grads = [f[1] for f in fx]\n",
    "            fx = [f[0] for f in fx]\n",
    "            self._gradient = self._exact_grad(grads)\n",
    "        else: \n",
    "            self._gradient = self._approx_grad(fx)\n",
    "        order = np.argsort(fx)\n",
    "                    \n",
    "        self._weights -= self._step_size * self._gradient * self._weights\n",
    "                \n",
    "        if fx[order[0]] < self._fbest:\n",
    "            self._fbest = fx[order[0]]\n",
    "            self._xbest = self._xs[order[0]]\n",
    "\n",
    "    # This should approximate the gradient. \n",
    "    # We are essentially approximating the partial derivative for each param\n",
    "    def _approx_grad(self, scores):\n",
    "        n = self._n_parameters\n",
    "        p = self._population_size\n",
    "        result = np.zeros(n)\n",
    "        for i in range(n):\n",
    "            for j in range(p):\n",
    "                for k in range(p):\n",
    "                    if j == k:\n",
    "                        continue\n",
    "                    result[i] += (scores[j + i*p] - scores[k + i*p]) / (self._user_xs[j + i*p][i] - self._user_xs[k + i*p][i])\n",
    "        return result / (p * (p-1))\n",
    "\n",
    "    # This function takes the gradients on each timestep t as input (so we are not computing the individual gradients here)\n",
    "    # We are using the individual gradients and take the average to get an estimation of the real gradients for each \n",
    "    # time step t\n",
    "    def _exact_grad(self, grads):\n",
    "        n = self._n_parameters\n",
    "        p = self._population_size\n",
    "        result = np.zeros(n)\n",
    "        for j in range(p):\n",
    "                    result += grads[j]\n",
    "        return result / p\n",
    "\n",
    "    def xbest(self):\n",
    "        \"\"\" See :meth:`Optimiser.xbest()`. \"\"\"\n",
    "        return self._xbest \n",
    "    \n",
    "    def weights(self):\n",
    "        return self._weights     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
