{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division\n",
    "from __future__ import print_function, unicode_literals\n",
    "import pints.toy as toy\n",
    "import pints\n",
    "import numpy as np\n",
    "import logging\n",
    "import math\n",
    "import sys\n",
    "from numpy import inf\n",
    "import copy \n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.transforms as transforms\n",
    "from logisticdraw import draw_cma_evolution\n",
    "from logisticdraw import model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IGOCMAFake(pints.PopulationBasedOptimiser):\n",
    "    \"\"\"\n",
    "    Finds the best parameters using the CMA-ES method described in [1, 2].\n",
    "\n",
    "    CMA-ES stands for Covariance Matrix Adaptation Evolution Strategy, and is\n",
    "    designed for non-linear derivative-free optimization problems.\n",
    "\n",
    "    *Extends:* :class:`PopulationBasedOptimiser`\n",
    "\n",
    "    [1] https://arxiv.org/pdf/1604.00772.pdf\n",
    "\n",
    "    [2] Hansen, Mueller, Koumoutsakos (2006) Reducing the time complexity of\n",
    "    the derandomized evolution strategy with covariance matrix adaptation\n",
    "    (CMA-ES).\n",
    "\n",
    "    Important note: The parameter parent_pop_size is the mu in the papers. It represents the size of a parent population\n",
    "        used to update our paramters.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x0, sigma0=0.5, boundaries=None):\n",
    "        super(IGOCMAFake, self).__init__(x0, sigma0, boundaries)\n",
    "\n",
    "        # Set initial state\n",
    "        self._running = False\n",
    "        self._ready_for_tell = False\n",
    "\n",
    "        # Best solution found\n",
    "        self._xbest = pints.vector(x0)\n",
    "        self._fbest = float('inf')\n",
    "\n",
    "        # Python logger\n",
    "        self._logger = logging.getLogger(__name__)\n",
    "\n",
    "        self._printing = False\n",
    "\n",
    "        self._counter = 0\n",
    "\n",
    "    def set_print(self, v):\n",
    "        self._printing = v\n",
    "\n",
    "    def ask(self):\n",
    "        \"\"\" See :meth:`Optimiser.ask()`. \"\"\"\n",
    "        # Initialise on first call\n",
    "        if not self._running:\n",
    "            self._initialise()\n",
    "\n",
    "        # Ready for tell now\n",
    "        self._ready_for_tell = True\n",
    "\n",
    "        # Create new samples\n",
    "        self._zs = np.array([np.random.multivariate_normal([0] * self._n_parameters, np.identity(self._n_parameters))\n",
    "                             for _ in range(self._population_size)])\n",
    "\n",
    "        self._ys = np.array([self._B.dot(self._D).dot(z) for z in self._zs])\n",
    "\n",
    "        self._xs = np.array([self._x0 + self._sigma0 * self._ys[i]\n",
    "                             for i in range(self._population_size)])\n",
    "\n",
    "        if self._manual_boundaries:\n",
    "            if isinstance(self._boundaries, pints.RectangularBoundaries):\n",
    "                upper = self._boundaries.upper()\n",
    "                lower = self._boundaries.lower()\n",
    "                for i in range(len(self._xs)):\n",
    "                    for j in range(len(self._xs[0])):\n",
    "                        if self._xs[i][j] > upper[j] or self._xs[i][j] < lower[j]:\n",
    "                            self._xs[i][j] = lower[j] + ((self._xs[i][j] - lower[j]) % (upper[j] - lower[j]))\n",
    "                    self._ys[i] = (self._xs[i] - self._x0) / self._sigma0\n",
    "                    self._zs[i] = np.linalg.inv(self._D).dot(np.linalg.inv(self._B)).dot(self._ys[i])\n",
    "        \n",
    "        self._user_xs = self._xs\n",
    "        self._user_zs = self._zs\n",
    "        self._user_ys = self._ys\n",
    "\n",
    "        # Set as read-only and return\n",
    "        self._user_xs.setflags(write=False)\n",
    "        return self._user_xs\n",
    "\n",
    "    def fbest(self):\n",
    "        \"\"\" See :meth:`Optimiser.fbest()`. \"\"\"\n",
    "        if not self._running:\n",
    "            return float('inf')\n",
    "        return self._fbest\n",
    "\n",
    "    def set_pop(self, n_pop):\n",
    "        self._population_size = n_pop\n",
    "    \n",
    "    def _initialise(self):\n",
    "        \"\"\"\n",
    "        Initialises the optimiser for the first iteration.\n",
    "        \"\"\"\n",
    "        assert (not self._running)\n",
    "\n",
    "        # Set boundaries, or use manual boundary checking\n",
    "        self._manual_boundaries = False\n",
    "        self._boundary_transform = None\n",
    "        if isinstance(self._boundaries, pints.RectangularBoundaries):\n",
    "            self._boundary_transform = pints.TriangleWaveTransform(\n",
    "                self._boundaries)\n",
    "        elif self._boundaries is not None:\n",
    "            self._manual_boundaries = True\n",
    "           \n",
    "        # CMA-ES wants a single standard deviation as input, use the smallest\n",
    "        # in the vector (if the user passed in a scalar, this will be the\n",
    "        # value used). THIS IS ALSO THE STEP SIZE\n",
    "        self._sigma0 = np.min(self._sigma0)\n",
    "\n",
    "        # Eigenvectors\n",
    "        self._B = np.identity(self._n_parameters)\n",
    "        # SquareRoot of Diagnonal of EigenValues\n",
    "        self._D = np.identity(self._n_parameters)\n",
    "        # Cov-matrix (also identity)\n",
    "        self._C = self._B.dot(self._D).dot(self._D.T).dot(self._B.T)\n",
    "\n",
    "        # Parent generation population size\n",
    "        # Not sure if the limitation to dim is good\n",
    "        # This limitation is supposed to prevent a mistake in the update of the Covariance\n",
    "        # matrix (C) with the rank mu update\n",
    "        self._parent_pop_size = self._population_size // 2\n",
    "\n",
    "        # Weights, all set equal for the moment (not sure how they are actually defined)\n",
    "        # Sum of all positive weights should be 1\n",
    "        self._W = [math.log((self._population_size + 1) / 2.) - math.log(i) for i in\n",
    "                   range(1, self._population_size + 1)]\n",
    "\n",
    "        # Inverse of the Sum of the first parent weights squared (variance effective selection mass)\n",
    "        self._muEff = np.sum(self._W[:self._parent_pop_size]) ** 2 / np.sum(np.square(self._W[:self._parent_pop_size]))\n",
    "\n",
    "        # Inverse of the Sum of the last weights squared (variance effective selection mass)\n",
    "        self._muEffMinus = np.sum(self._W[self._parent_pop_size:]) ** 2 / np.sum(\n",
    "            np.square(self._W[self._parent_pop_size:]))\n",
    "\n",
    "        # cumulation, evolution paths, used to update Cov matrix and sigma)\n",
    "        self._pc = np.zeros(self._n_parameters)\n",
    "        self._psig = np.zeros(self._n_parameters)\n",
    "\n",
    "        # learning rate for the mean\n",
    "        self._cm = 1\n",
    "\n",
    "        # Decay rate of the evolution path for C\n",
    "        self._ccov = (4 + self._muEff / self._n_parameters) / (\n",
    "                self._n_parameters + 4 + 2 * self._muEff / self._n_parameters)\n",
    "\n",
    "        # Decay rate of the evolution path for sigma\n",
    "        self._csig = (2 + self._muEff) / (self._n_parameters + 5 + self._muEff)\n",
    "\n",
    "        # See rank-1 vs rank-mu updates\n",
    "        # Learning rate for rank-1 update\n",
    "        self._c1 = 2 / ((self._n_parameters + 1.3) ** 2 + self._muEff)\n",
    "\n",
    "        # Learning rate for rank-mu update\n",
    "        self._cmu = min(2 * (self._muEff - 2 + 1 / self._muEff) / ((self._n_parameters + 2) ** 2 + self._muEff)\n",
    "                        , 1 - self._c1)\n",
    "        self._cm = self._cmu\n",
    "        \n",
    "        \n",
    "        # Damping of the step-size (sigma0) update\n",
    "        self._dsig = 1 + 2 * max(0., math.sqrt((self._muEff - 1) / (self._n_parameters + 1)) - 1) + self._csig\n",
    "\n",
    "        # Parameters from the Table 1 of [1]\n",
    "        alpha_mu = 1 + self._c1 / self._cmu\n",
    "        alpha_mueff = 1 + 2 * self._muEffMinus / (self._muEff + 2)\n",
    "        alpha_pos_def = (1 - self._c1 - self._cmu) / (self._n_parameters * self._cmu)\n",
    "\n",
    "        # Rescaling the weights\n",
    "        sum_pos = sum([self._W[i] if self._W[i] > 0 else 0 for i in range(self._population_size)])\n",
    "        sum_neg = sum([self._W[i] if self._W[i] < 0 else 0 for i in range(self._population_size)])\n",
    "\n",
    "        self._W = [self._W[i] / sum_pos\n",
    "                   if self._W[i] >= 0\n",
    "                   else self._W[i] * min(alpha_mu, alpha_mueff, alpha_pos_def) / -sum_neg\n",
    "                   for i in range(self._population_size)]\n",
    "\n",
    "        # CMAES always seeds np.random, whether you ask it too or not, so to\n",
    "        # get consistent debugging output, we should always pass in a seed.\n",
    "        # Instead of using a fixed number (which would be bad), we can use a\n",
    "        # randomly generated number: This will ensure pseudo-randomness, but\n",
    "        # produce consistent results if np.random has been seeded before\n",
    "        # calling.\n",
    "        self._seed = 2 ** 31\n",
    "        np.random.seed(self._seed)\n",
    "\n",
    "        # Update optimiser state\n",
    "        self._running = True\n",
    "\n",
    "    def name(self):\n",
    "        \"\"\" See :meth:`Optimiser.name()`. \"\"\"\n",
    "        return 'Covariance Matrix Adaptation Evolution Strategy (CMA-ES)'\n",
    "\n",
    "    def running(self):\n",
    "        \"\"\" See :meth:`Optimiser.running()`. \"\"\"\n",
    "        return self._running\n",
    "\n",
    "    def stop(self):\n",
    "        diag_D = np.diagonal(self._D)\n",
    "        # We use the condition number defined in the pycma code at\n",
    "        # https://github.com/CMA-ES/pycma/blob/3abf6900e04d0619f4bfba989dde9e093fa8e1ba/cma/evolution_strategy.py#L2965\n",
    "        if (np.max(diag_D) / np.min(diag_D)) ** 2 > 1e14:\n",
    "            return 'Ill-conditionned covariance matrix'\n",
    "        return False\n",
    "\n",
    "    def _suggested_population_size(self):\n",
    "        \"\"\" See :meth:`Optimiser._suggested_population_size(). \"\"\"\n",
    "        return 4 + int(3 * np.log(self._n_parameters))\n",
    "\n",
    "    def tell(self, fx):\n",
    "        \"\"\" See :meth:`Optimiser.tell()`. \"\"\"\n",
    "        if not self._ready_for_tell:\n",
    "            raise Exception('ask() not called before tell()')\n",
    "        self._ready_for_tell = False\n",
    "\n",
    "        self._counter += 1\n",
    "\n",
    "        fx[fx == np.inf] = sys.maxsize\n",
    "\n",
    "        # Get the best xs according to the fx results\n",
    "        order = np.argsort(fx)\n",
    "        xs_bests = np.array(self._user_xs[order])\n",
    "        ys_bests = np.array(self._user_ys[order])  # = np.array((xs_bests - self._x0) / self._sigma0)\n",
    "\n",
    "        # Update the mean\n",
    "        self._x0 = self._x0 + self._cm * np.sum(np.multiply((xs_bests[:self._parent_pop_size] - self._x0).T,\n",
    "                                                            self._W[:self._parent_pop_size]).T, 0)\n",
    "\n",
    "        # Update the Covariance matrix:\n",
    "        # First carry on some of the previous value\n",
    "        # Add the rank-mu update\n",
    "        rankmu = self._cmu * np.sum(np.multiply(np.array([np.outer(y, y) - self._C for y in ys_bests]).T,\n",
    "                                                self._W).T, 0)\n",
    "        self._C = self._C  + rankmu\n",
    "\n",
    "        # Update B and D\n",
    "        self._C = np.triu(self._C) + np.triu(self._C, 1).T\n",
    "        [eigenvals, self._B] = np.linalg.eigh(self._C)\n",
    "\n",
    "        if self.stop():\n",
    "            return False\n",
    "\n",
    "        self._D = np.sqrt(np.diag(eigenvals))\n",
    "\n",
    "        if self._fbest > fx[order[0]]:\n",
    "            self._fbest = fx[order[0]]\n",
    "            self._xbest = xs_bests[0]\n",
    "\n",
    "    def print_all_info(self):\n",
    "        print(\"parents weights \", self._W[:self._parent_pop_size])\n",
    "        print(\"other weights\", self._W[self._parent_pop_size:])\n",
    "        print(\"c1\", self._c1)\n",
    "        print(\"cmu\", self._cmu)\n",
    "        print(\"Mean\", self._x0)\n",
    "        print(\"Covariance matrix\", self._C)\n",
    "        print(\"B or EIGENVECTORS\", self._B)\n",
    "        print(\"D\", self._D)\n",
    "\n",
    "    def rankmu(self):\n",
    "        return self._rankMu_update\n",
    "\n",
    "    def cov(self):\n",
    "        return self._C\n",
    "\n",
    "    def mean(self):\n",
    "        return self._x0\n",
    "\n",
    "    def xbest(self):\n",
    "        \"\"\" See :meth:`Optimiser.xbest()`. \"\"\"\n",
    "        if self._running:\n",
    "            return np.array(self._xbest, copy=True)\n",
    "        return np.array([float('inf')] * self._n_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = model_dict['Logistic']\n",
    "x0 = value['x0']\n",
    "cma = IGOCMAFake(x0)\n",
    "draw_cma_evolution(value['model'], value['real_parameters'], value['times'], cma, 3,fakeIGO=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = model_dict['Logistic']\n",
    "x0 = value['x0']\n",
    "cma = IGOCMAFake(x0)\n",
    "pop = 10\n",
    "cma.set_pop(pop)\n",
    "draw_cma_evolution(value['model'], value['real_parameters'], value['times'], cma, pop // 2, fakeIGO=True ,iterations=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = model_dict['Logistic']\n",
    "x0 = value['x0']\n",
    "cma = IGOCMAFake(x0)\n",
    "pop = 20\n",
    "cma.set_pop(pop)\n",
    "draw_cma_evolution(value['model'], value['real_parameters'], value['times'], cma, pop // 2, fakeIGO=True, iterations=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = model_dict['Logistic']\n",
    "x0 = value['x0']\n",
    "cma = IGOCMAFake(x0)\n",
    "pop = 30\n",
    "cma.set_pop(pop)\n",
    "draw_cma_evolution(value['model'], value['real_parameters'], value['times'], cma, pop // 2, fakeIGO=True, iterations=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = model_dict['Logistic']\n",
    "x0 = value['x0']\n",
    "cma = IGOCMAFake(x0)\n",
    "pop = 40\n",
    "cma.set_pop(pop)\n",
    "draw_cma_evolution(value['model'], value['real_parameters'], value['times'], cma, pop // 2, fakeIGO=True, iterations=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = model_dict['Logistic']\n",
    "x0 = value['x0']\n",
    "cma = IGOCMAFake(x0)\n",
    "pop = 50\n",
    "cma.set_pop(pop)\n",
    "draw_cma_evolution(value['model'], value['real_parameters'], value['times'], cma, pop // 2, fakeIGO=True, iterations=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = model_dict['Logistic']\n",
    "x0 = value['x0']\n",
    "cma = IGOCMAFake(x0)\n",
    "pop = 60\n",
    "cma.set_pop(pop)\n",
    "draw_cma_evolution(value['model'], value['real_parameters'], value['times'], cma, pop // 2, fakeIGO=True, iterations=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = model_dict['Logistic']\n",
    "x0 = value['x0']\n",
    "cma = IGOCMAFake(x0)\n",
    "pop = 70\n",
    "cma.set_pop(pop)\n",
    "draw_cma_evolution(value['model'], value['real_parameters'], value['times'], cma, pop // 2, fakeIGO=True, iterations=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = model_dict['Logistic']\n",
    "x0 = value['x0']\n",
    "cma = IGOCMAFake(x0)\n",
    "pop = 90\n",
    "cma.set_pop(pop)\n",
    "draw_cma_evolution(value['model'], value['real_parameters'], value['times'], cma, pop // 2, fakeIGO=True, iterations=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = model_dict['Logistic']\n",
    "x0 = value['x0']\n",
    "cma = IGOCMAFake(x0)\n",
    "pop = 95\n",
    "cma.set_pop(pop)\n",
    "draw_cma_evolution(value['model'], value['real_parameters'], value['times'], cma, pop // 2, fakeIGO=True, iterations=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = model_dict['Logistic']\n",
    "x0 = value['x0']\n",
    "cma = IGOCMAFake(x0)\n",
    "pop = 99\n",
    "cma.set_pop(pop)\n",
    "draw_cma_evolution(value['model'], value['real_parameters'], value['times'], cma, pop // 2, fakeIGO=True, iterations=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = model_dict['Logistic']\n",
    "x0 = value['x0']\n",
    "cma = IGOCMAFake(x0)\n",
    "pop = 100\n",
    "cma.set_pop(pop)\n",
    "draw_cma_evolution(value['model'], value['real_parameters'], value['times'], cma, pop // 2, fakeIGO=True, iterations=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
